<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  
  <title>黄河水澄的技术专栏</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  <meta property="og:type" content="website">
<meta property="og:title" content="黄河水澄的技术专栏">
<meta property="og:url" content="https://debugtheuniverse.github.io/page/2/index.html">
<meta property="og:site_name" content="黄河水澄的技术专栏">
<meta property="og:locale">
<meta property="article:author" content="Jim Huang">
<meta name="twitter:card" content="summary">
  
    <link rel="alternate" href="/atom.xml" title="黄河水澄的技术专栏" type="application/atom+xml">
  
  
    <link rel="shortcut icon" href="/favicon.png">
  
  
  
<link rel="stylesheet" href="/css/style.css">

  
    
<link rel="stylesheet" href="/fancybox/jquery.fancybox.min.css">

  
  
<meta name="generator" content="Hexo 7.1.1"></head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">黄河水澄的技术专栏</a>
      </h1>
      
        <h2 id="subtitle-wrap">
          <a href="/" id="subtitle">分享有用的知识</a>
        </h2>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"><span class="fa fa-bars"></span></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
        
          <a class="nav-icon" href="/atom.xml" title="RSS Feed"><span class="fa fa-rss"></span></a>
        
        <a class="nav-icon nav-search-btn" title="Suche"><span class="fa fa-search"></span></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Suche"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="https://DebugTheUniverse.github.io"></form>
      </div>
    </div>
  </div>
</header>

      <div class="outer">
        <section id="main">
  
    <article id="post-目标识别" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2024/04/20/%E7%9B%AE%E6%A0%87%E8%AF%86%E5%88%AB/" class="article-date">
  <time class="dt-published" datetime="2024-04-20T09:13:48.789Z" itemprop="datePublished">2024-04-20</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="p-name article-title" href="/2024/04/20/%E7%9B%AE%E6%A0%87%E8%AF%86%E5%88%AB/">目标识别</a>
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <h3 id="Deep-Residual-Learning-for-Image-Recognition"><a href="#Deep-Residual-Learning-for-Image-Recognition" class="headerlink" title="Deep Residual Learning for Image Recognition"></a>Deep Residual Learning for Image Recognition</h3><p>Kaiming He大神2015发表</p>
<h4 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h4><p>越深的model越难训练。而大神的方法可以比以前网络更深（152层）的同时还易于optimize。</p>
<h4 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h4><p>深度学习刚开始认为model层数越多越好，然后发现到一定程度增加层数会有退化degradation的效果，所谓梯度消失&#x2F;爆炸问题。<br>所以这里提出的方法是F(x)+x，在网络中就相当于增加可以跨越一层或者多层的捷径，关键是这操作还不需要增加模型参数和计算复杂度。<br>摆试验结论：对照组层数增加误差增加，而resnet轻松享受增加层数带来的好处</p>
<h4 id="试验结果"><a href="#试验结果" class="headerlink" title="试验结果"></a>试验结果</h4><p>单模型resnet152的top-5 error达到了4.49%，6个不同深度的模型组合达到了 3.57%<br>普通网络18层精度比34层高。而resnet18比普通18收敛快。<br>resnet1202比resnet101差，可能是因为参数相对于数据集太大导致。</p>
<h3 id="PVANet-Lightweight-Deep-Neural-Networks-for-Real-time-Object-Detection"><a href="#PVANet-Lightweight-Deep-Neural-Networks-for-Real-time-Object-Detection" class="headerlink" title="PVANet : Lightweight Deep Neural Networks for Real-time Object Detection"></a>PVANet : Lightweight Deep Neural Networks for Real-time Object Detection</h3><p>Sanghoon Hong 2016发表</p>
<h4 id="Abstract-1"><a href="#Abstract-1" class="headerlink" title="Abstract"></a>Abstract</h4><p>减少计算量的情况下提高多类别分类任务精度，使用less channels with more layers。结果是voc2007的mAP达83.8%，voc2012达82.5%（第二）。计算量是resnet101的12.3%。</p>
<h3 id="Rich-feature-hierarchies-for-accurate-object-detection-and-semantic-segmentation-RCNN"><a href="#Rich-feature-hierarchies-for-accurate-object-detection-and-semantic-segmentation-RCNN" class="headerlink" title="Rich feature hierarchies for accurate object detection and semantic segmentation (RCNN)"></a>Rich feature hierarchies for accurate object detection and semantic segmentation (RCNN)</h3><p>Ross Girshick 2014发表</p>
<h4 id="Abstract-2"><a href="#Abstract-2" class="headerlink" title="Abstract"></a>Abstract</h4><p>提出方法比先前的组合模型在VOC2012提高mAP约30%，达到53.3%。</p>
<h4 id="Introduction-1"><a href="#Introduction-1" class="headerlink" title="Introduction"></a>Introduction</h4><p>关注如何用一个深层模型来定位目标，仅使用少量标注检测数据训练一个高容量的模型<br>定位此前滑动窗口被用了近20年，最佳模型OverFeat在ILSVRC2013的mAP是24.3%，而rcnn达到了31.4%。<br>有监督的预训练加上特定领域的微调。</p>
<ol>
<li>输入图片</li>
<li>提取约2000个与类别无关的proposals</li>
<li>使用一个大CNN模型提取每个proposal的特征</li>
<li>使用特定类别的SVM对proposals进行分类</li>
</ol>
<h4 id="bbox-regression"><a href="#bbox-regression" class="headerlink" title="bbox regression"></a>bbox regression</h4><p>将预测的bbox P与gt的bbox G之间做一个映射<br>G_x &#x3D; P_w * d_x(P) + P_x<br>G_y &#x3D; P_h * d_y(P) + P_y<br>G_w &#x3D; P_w * exp(d_w(P))<br>G_h &#x3D; P_h * exp(d_h(P))</p>
<p>第pool5特征的线性函数<br>d_#(P) &#x3D; w_#^T * phi_5(P)  其中#表示x,y,w,h</p>
<p>用ridge regression学习w_#，而其target<br>t_x &#x3D; (G_x - P_x)&#x2F;P_w<br>t_y &#x3D; (G_y - P_y)&#x2F;P_h<br>t_w &#x3D; log(G_w&#x2F;P_w)<br>t_h &#x3D; log(G_h&#x2F;P_h)</p>
<p>只对与gt的IoU高于0.6的P进行学习，其他的丢弃</p>
<h3 id="Spatial-Pyramid-Pooling-in-Deep-Convolutional-Networks-for-Visual-Recognition"><a href="#Spatial-Pyramid-Pooling-in-Deep-Convolutional-Networks-for-Visual-Recognition" class="headerlink" title="Spatial Pyramid Pooling in Deep Convolutional Networks for Visual Recognition"></a>Spatial Pyramid Pooling in Deep Convolutional Networks for Visual Recognition</h3><p>Kaiming He 2014发布<br>SPP-net可以确保输出的尺寸不变，不管输入图片的尺寸。这个方法只计算一次特征图，然后对随机区域pool到固定长度的representation，然后训练detector。<br>实现比RCNN快24-102倍情况下效果还略好。<br>对特征图分别进行全部pool得1个256维的向量，再分4块pool得4个256维向量，再分16块pool得到16个256维向量，把这些向量组合起来，得到21*256维的向量（固定长度），再接全连接层。</p>
<h3 id="Fast-R-CNN-Ross-Girshick"><a href="#Fast-R-CNN-Ross-Girshick" class="headerlink" title="Fast R-CNN Ross Girshick"></a>Fast R-CNN Ross Girshick</h3><p>训练VGG比R-CNN快9倍，测试快213倍，精度还要高些。比SPPnet训练3倍，测试快10倍，精度也高些。<br>一个模型直接包括定位和识别。<br>RCNN慢是因为每次都需要重新计算特征图，而SPPnet一次计算特征图有共享的效果所以快。这两种方法也都是需要分步操作的。</p>
<ol>
<li>输入图像和多个roi到全卷积网络FCN，输入的ROI被prejecting到特征图上面的roi。</li>
<li>对特征图roi进行pool到固定尺寸，再使用全连接层FCs变成特征</li>
<li>每个特征roi都最终连了两个输出：softmax probabilities、per-class bbox regression offsets</li>
<li>使用多任务loss进行end-to-end 训练。</li>
</ol>
<p>Truncated SVD减少推理时间30%。</p>
<h3 id="Faster-R-CNN-Towards-Real-Time-Object-Detection-with-Region-Proposal-Networks"><a href="#Faster-R-CNN-Towards-Real-Time-Object-Detection-with-Region-Proposal-Networks" class="headerlink" title="Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks"></a>Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks</h3><p>Shaoqing Ren 2015<br>提出RPN网络，将全卷积的特征与检测分享，同时给出目标位置和类别分数，达到接近零cost的proposal。拿下ILSVRC and COCO的2015第一名。</p>
<p>在共享的特征图的最后一层上，用一个nxn的窗口进行滑动（3x3感受野约171ZF和228VGG）,nxn进行卷积引出两个分支cls和reg，每个窗口设定了最大proposal数量k，因此cls为是目标或不是目标2个因此是2k个，而reg就是4k个了</p>
<h3 id="You-Only-Look-Once-Unified-Real-Time-Object-Detection"><a href="#You-Only-Look-Once-Unified-Real-Time-Object-Detection" class="headerlink" title="You Only Look Once: Unified, Real-Time Object Detection"></a>You Only Look Once: Unified, Real-Time Object Detection</h3><p>Joseph Redmon 2015<br>将目标检测问题构建为regression用以获得分离的边界框类别概率。极快。相较于其他方法的定位精度稍逊，但不太可能误判背景。</p>
<ol>
<li>resize输入到448x448</li>
<li>运行cnn</li>
<li>根据模型的confidence对检测结果进行阈值处理</li>
</ol>
<p>YOLO看全局信息，比fast rcnn少一半的背景误差。</p>
<p>将输入图片划分为SxS的grid，每个grid预测B个bbox和C个概率，因此编成S * S * (B<em>5 + C)的预测<br>每个bbox后面附赠一个有目标的confidence，因此是B</em>5<br>类别数量C</p>
<p>YOLO的泛化性能强。即只在VOC2007训练，然后在Picasso dataset和people-art dataset做测试，比R-CNN强（而R-CNN在VOC2007的mAP最高）</p>
<h3 id="Inside-Outside-Net-Detecting-Objects-in-Context-with-Skip-Pooling-and-Recurrent-Neural-Networks"><a href="#Inside-Outside-Net-Detecting-Objects-in-Context-with-Skip-Pooling-and-Recurrent-Neural-Networks" class="headerlink" title="Inside-Outside Net: Detecting Objects in Context with Skip Pooling and Recurrent Neural Networks"></a>Inside-Outside Net: Detecting Objects in Context with Skip Pooling and Recurrent Neural Networks</h3><p>Sean Bell 2015<br>PASCAL VOC 2012的mAP达到76.4%，在MS COCO dataset，mAP有33.1%<br>将roi外部的contextual信息用RNNs考虑进来，其余部分有点像SPPnet的操作+RCNN的detection</p>
<h3 id="R-FCN-Object-Detection-via-Region-based-Fully-Convolutional-Networks"><a href="#R-FCN-Object-Detection-via-Region-based-Fully-Convolutional-Networks" class="headerlink" title="R-FCN: Object Detection via Region-based Fully Convolutional Networks"></a>R-FCN: Object Detection via Region-based Fully Convolutional Networks</h3><p>Jifeng Dai</p>
<p>VOC2007的mAP达83.6%，比Faster R-CNN快2.5-40倍</p>
<h3 id="SSD-Single-Shot-MultiBox-Detector"><a href="#SSD-Single-Shot-MultiBox-Detector" class="headerlink" title="SSD: Single Shot MultiBox Detector"></a>SSD: Single Shot MultiBox Detector</h3><p>Wei Liu</p>
<p>voc2007达到mAP 72.1%，比Faster rcnn快<br>有8x8和4x4的特征图grid，在每一个位置有几个不同长宽比的默认框，将其与gt框重叠的为positive，其余作为negative，每个框有4个坐标和c个confidence</p>
<h3 id="YOLO9000-YOLO-V2"><a href="#YOLO9000-YOLO-V2" class="headerlink" title="YOLO9000 (YOLO V2)"></a>YOLO9000 (YOLO V2)</h3><p>应用了BN，提高了输入resolution，不限定输入图像尺寸，等操作，better、faster、stronger</p>
<h3 id="YOLOv3"><a href="#YOLOv3" class="headerlink" title="YOLOv3"></a>YOLOv3</h3><p>借鉴Resnet设计的darknet53，提高了小目标检测能力；增加了多尺度特征融合，即下采样和上采样融合。将softmax改为logistic支持多标签。<br>YOLO原作者因为技术被用作军事和隐私而退出。</p>
<h3 id="YOLOv4"><a href="#YOLOv4" class="headerlink" title="YOLOv4"></a>YOLOv4</h3><p>ultralytics 增加了一些功能，权序列连接 (WRC)、跨阶段部分连接 (CSP)、交叉迷你批归一化 (CmBN)、自对抗训练 (SAT)、误激活、马赛克数据增强、DropBlock 正则化和 CIoU 损失</p>
<h3 id="YOLOv5"><a href="#YOLOv5" class="headerlink" title="YOLOv5"></a>YOLOv5</h3><p>ultralytics 无锚点分割Ultralytics Head，优化准确性与速度之间的权衡，多种预训练模型</p>
<h3 id="YOLOv6"><a href="#YOLOv6" class="headerlink" title="YOLOv6"></a>YOLOv6</h3><p>美团<br>双向串行 (BiC) 模块：YOLOv6 在探测器的颈部引入了双向并联（BiC）模块，可增强定位信号并提高性能，而速度降低可忽略不计。<br>锚点辅助训练（AAT）策略：该模型提出的 AAT 可同时享受基于锚和无锚范式的优势，而不会降低推理效率。<br>增强型骨干和颈部设计：通过深化 YOLOv6，在骨干和颈部加入另一个阶段，该模型在高分辨率输入的 COCO 数据集上实现了最先进的性能。<br>自蒸馏策略：为了提高 YOLOv6 较小模型的性能，我们采用了一种新的自蒸馏策略，在训练过程中增强辅助回归分支，在推理过程中去除辅助回归分支，以避免速度明显下降。</p>
<h3 id="YOLOv7-Trainable-bag-of-freebies-sets-new-state-of-the-art-for-real-time-object-detectors"><a href="#YOLOv7-Trainable-bag-of-freebies-sets-new-state-of-the-art-for-real-time-object-detectors" class="headerlink" title="YOLOv7: Trainable bag-of-freebies sets new state-of-the-art for real-time object detectors"></a>YOLOv7: Trainable bag-of-freebies sets new state-of-the-art for real-time object detectors</h3><p>Chien-Yao Wang 2022<br>模型重新参数化：YOLOv7 提出了一种有计划的重新参数化模型，这是一种适用于不同网络层的策略，具有梯度传播路径的概念。</p>
<p>动态标签分配：多输出层模型的训练提出了一个新问题：”如何为不同分支的输出分配动态目标？为了解决这个问题，YOLOv7 引入了一种新的标签分配方法，即从粗到细的引导标签分配法。</p>
<p>扩展和复合缩放YOLOv7 为实时对象检测器提出了 “扩展 “和 “复合缩放 “方法，可有效利用参数和计算。</p>
<p>效率：YOLOv7 提出的方法能有效减少最先进的实时物体检测器约 40% 的参数和 50% 的计算量，推理速度更快，检测精度更高。</p>
<h3 id="YOLOv8"><a href="#YOLOv8" class="headerlink" title="YOLOv8"></a>YOLOv8</h3><p>Ultralytics<br>先进的骨干和颈部架构： YOLOv8 采用了最先进的骨干和颈部架构，从而提高了特征提取和物体检测性能。<br>无锚分裂Ultralytics 头： YOLOv8 采用无锚分裂Ultralytics 头，与基于锚的方法相比，它有助于提高检测过程的准确性和效率。<br>优化精度与速度之间的权衡： YOLOv8 专注于保持精度与速度之间的最佳平衡，适用于各种应用领域的实时目标检测任务。<br>各种预训练模型： YOLOv8 提供一系列预训练模型，以满足各种任务和性能要求，从而更容易为您的特定用例找到合适的模型。</p>
<h3 id="YOLOv9"><a href="#YOLOv9" class="headerlink" title="YOLOv9"></a>YOLOv9</h3><p>YOLOv9 在其架构中加入了可逆函数，以降低信息退化的风险<br>PGI 是 YOLOv9 为解决信息瓶颈问题而引入的一个新概念，可确保在深层网络中保留重要数据。这样就能生成可靠的梯度，促进模型的准确更新，提高整体检测性能。<br>GELAN 是一项战略性的架构进步，使 YOLOv9 能够实现更高的参数利用率和计算效率。<br>YOLOv9c 模型尤其凸显了架构优化的有效性。与 YOLOv7 AF 相比，它的运行参数减少了 42%，计算需求减少了 21%，但精度却不相上下，这表明 YOLOv9 的效率有了显著提高。此外，YOLOv9e 模型还为大型模型设立了新标准，其参数比 YOLOv7 AF 少 15%，计算需求比 YOLOv7 AF 少 25%。 YOLOv8x相比，参数减少了 15%，计算需求减少了 25%，同时 AP 增量提高了 1.7%。<br>这些结果展示了 YOLOv9 在模型设计方面的战略性进步，强调了它在提高效率的同时并没有降低实时物体检测任务所必需的精度。该模型不仅突破了性能指标的界限，而且强调了计算效率的重要性，使其成为计算机视觉领域的一项关键性发展。</p>
<h3 id="Segment-Anything"><a href="#Segment-Anything" class="headerlink" title="Segment Anything"></a>Segment Anything</h3><p>Alexander Kirillov 2023<br>在大语言模型中网络级别的大数据训练可以让NLP模型泛化到未见数据。这种容量与prompt engineering常在一起使用。cv目前缺少大量的数据。<br>提出SA-1B分割数据集，比现有任何都大400倍以上</p>
<p>自动标注是SAM 的一项重要功能，允许用户使用预先训练好的检测模型生成分割数据集。这一功能可以快速、准确地标注大量图像，避免了耗时的人工标注。</p>
<h3 id="RT-DTER"><a href="#RT-DTER" class="headerlink" title="RT-DTER"></a>RT-DTER</h3><p>百度 2023<br>极快，效果好的一个detection model</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://debugtheuniverse.github.io/2024/04/20/%E7%9B%AE%E6%A0%87%E8%AF%86%E5%88%AB/" data-id="clvg47z9s000020ukftzs6qae" data-title="目标识别" class="article-share-link"><span class="fa fa-share">Teilen</span></a>
      
      
      
    </footer>
  </div>
  
</article>



  
    <article id="post-计算机视觉入门" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2024/04/20/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89%E5%85%A5%E9%97%A8/" class="article-date">
  <time class="dt-published" datetime="2024-04-20T01:07:41.765Z" itemprop="datePublished">2024-04-20</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="p-name article-title" href="/2024/04/20/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89%E5%85%A5%E9%97%A8/">计算机视觉入门</a>
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <h3 id="卷积网络图像分类器"><a href="#卷积网络图像分类器" class="headerlink" title="卷积网络图像分类器"></a>卷积网络图像分类器</h3><p>一个卷积神经网络通常包含了base和head两个部分。base是用于提取特征，head用于对特征进行分类（就与机器学习里面的一样）。</p>
<h4 id="读取数据"><a href="#读取数据" class="headerlink" title="读取数据"></a>读取数据</h4><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Imports</span></span><br><span class="line"><span class="keyword">import</span> os, warnings</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> gridspec</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">from</span> tensorflow.keras.preprocessing <span class="keyword">import</span> image_dataset_from_directory</span><br><span class="line"></span><br><span class="line"><span class="comment"># Reproducability</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">set_seed</span>(<span class="params">seed=<span class="number">31415</span></span>):</span><br><span class="line">    np.random.seed(seed)</span><br><span class="line">    tf.random.set_seed(seed)</span><br><span class="line">    os.environ[<span class="string">&#x27;PYTHONHASHSEED&#x27;</span>] = <span class="built_in">str</span>(seed)</span><br><span class="line">    os.environ[<span class="string">&#x27;TF_DETERMINISTIC_OPS&#x27;</span>] = <span class="string">&#x27;1&#x27;</span></span><br><span class="line">set_seed(<span class="number">31415</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Set Matplotlib defaults</span></span><br><span class="line">plt.rc(<span class="string">&#x27;figure&#x27;</span>, autolayout=<span class="literal">True</span>)</span><br><span class="line">plt.rc(<span class="string">&#x27;axes&#x27;</span>, labelweight=<span class="string">&#x27;bold&#x27;</span>, labelsize=<span class="string">&#x27;large&#x27;</span>,</span><br><span class="line">       titleweight=<span class="string">&#x27;bold&#x27;</span>, titlesize=<span class="number">18</span>, titlepad=<span class="number">10</span>)</span><br><span class="line">plt.rc(<span class="string">&#x27;image&#x27;</span>, cmap=<span class="string">&#x27;magma&#x27;</span>)</span><br><span class="line">warnings.filterwarnings(<span class="string">&quot;ignore&quot;</span>) <span class="comment"># to clean up output cells</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Load training and validation sets</span></span><br><span class="line">ds_train_ = image_dataset_from_directory(</span><br><span class="line">    <span class="string">&#x27;../input/car-or-truck/train&#x27;</span>,</span><br><span class="line">    labels=<span class="string">&#x27;inferred&#x27;</span>,</span><br><span class="line">    label_mode=<span class="string">&#x27;binary&#x27;</span>,</span><br><span class="line">    image_size=[<span class="number">128</span>, <span class="number">128</span>],</span><br><span class="line">    interpolation=<span class="string">&#x27;nearest&#x27;</span>,</span><br><span class="line">    batch_size=<span class="number">64</span>,</span><br><span class="line">    shuffle=<span class="literal">True</span>,</span><br><span class="line">)</span><br><span class="line">ds_valid_ = image_dataset_from_directory(</span><br><span class="line">    <span class="string">&#x27;../input/car-or-truck/valid&#x27;</span>,</span><br><span class="line">    labels=<span class="string">&#x27;inferred&#x27;</span>,</span><br><span class="line">    label_mode=<span class="string">&#x27;binary&#x27;</span>,</span><br><span class="line">    image_size=[<span class="number">128</span>, <span class="number">128</span>],</span><br><span class="line">    interpolation=<span class="string">&#x27;nearest&#x27;</span>,</span><br><span class="line">    batch_size=<span class="number">64</span>,</span><br><span class="line">    shuffle=<span class="literal">False</span>,</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Data Pipeline</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">convert_to_float</span>(<span class="params">image, label</span>):</span><br><span class="line">    image = tf.image.convert_image_dtype(image, dtype=tf.float32)</span><br><span class="line">    <span class="keyword">return</span> image, label</span><br><span class="line"></span><br><span class="line">AUTOTUNE = tf.data.experimental.AUTOTUNE</span><br><span class="line">ds_train = (</span><br><span class="line">    ds_train_</span><br><span class="line">    .<span class="built_in">map</span>(convert_to_float)</span><br><span class="line">    .cache()</span><br><span class="line">    .prefetch(buffer_size=AUTOTUNE)</span><br><span class="line">)</span><br><span class="line">ds_valid = (</span><br><span class="line">    ds_valid_</span><br><span class="line">    .<span class="built_in">map</span>(convert_to_float)</span><br><span class="line">    .cache()</span><br><span class="line">    .prefetch(buffer_size=AUTOTUNE)</span><br><span class="line">)</span><br></pre></td></tr></table></figure>

<h4 id="读取预训练base"><a href="#读取预训练base" class="headerlink" title="读取预训练base"></a>读取预训练base</h4><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">pretrained_base = tf.keras.models.load_model(</span><br><span class="line">    <span class="string">&#x27;../input/cv-course-models/cv-course-models/vgg16-pretrained-base&#x27;</span>,</span><br><span class="line">)</span><br><span class="line">pretrained_base.trainable = <span class="literal">False</span> <span class="comment"># 直接使用在大规模数据训练好的head也叫Transfer Learning，不在小规模数据中改动</span></span><br></pre></td></tr></table></figure>

<h4 id="接上head后训练"><a href="#接上head后训练" class="headerlink" title="接上head后训练"></a>接上head后训练</h4><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> tensorflow <span class="keyword">import</span> keras</span><br><span class="line"><span class="keyword">from</span> tensorflow.keras <span class="keyword">import</span> layers</span><br><span class="line"></span><br><span class="line">model = keras.Sequential([</span><br><span class="line">    pretrained_base,</span><br><span class="line">    layers.Flatten(),</span><br><span class="line">    layers.Dense(<span class="number">6</span>, activation=<span class="string">&#x27;relu&#x27;</span>),</span><br><span class="line">    layers.Dense(<span class="number">1</span>, activation=<span class="string">&#x27;sigmoid&#x27;</span>),</span><br><span class="line">])</span><br><span class="line"></span><br><span class="line">model.<span class="built_in">compile</span>(</span><br><span class="line">    optimizer=<span class="string">&#x27;adam&#x27;</span>,</span><br><span class="line">    loss=<span class="string">&#x27;binary_crossentropy&#x27;</span>,</span><br><span class="line">    metrics=[<span class="string">&#x27;binary_accuracy&#x27;</span>],</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">history = model.fit(</span><br><span class="line">    ds_train,</span><br><span class="line">    validation_data=ds_valid,</span><br><span class="line">    epochs=<span class="number">30</span>,</span><br><span class="line">    verbose=<span class="number">0</span>,</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"></span><br><span class="line">history_frame = pd.DataFrame(history.history)</span><br><span class="line">history_frame.loc[:, [<span class="string">&#x27;loss&#x27;</span>, <span class="string">&#x27;val_loss&#x27;</span>]].plot()</span><br><span class="line">history_frame.loc[:, [<span class="string">&#x27;binary_accuracy&#x27;</span>, <span class="string">&#x27;val_binary_accuracy&#x27;</span>]].plot()</span><br></pre></td></tr></table></figure>

<h4 id="filter-detect-condense"><a href="#filter-detect-condense" class="headerlink" title="filter detect condense"></a>filter detect condense</h4><p>在head中，使用filters对input图像进行过滤，然后使用relu实现detect效果，再用maxpooling实现condense<br>先relu后maxpooling就有intensifying的效果</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> tensorflow <span class="keyword">import</span> keras</span><br><span class="line"><span class="keyword">from</span> tensorflow.keras <span class="keyword">import</span> layers</span><br><span class="line"></span><br><span class="line">model = keras.Sequential([</span><br><span class="line">    layers.Conv2D(filters=<span class="number">64</span>, kernel_size=<span class="number">3</span>), <span class="comment"># activation is None</span></span><br><span class="line">    layers.MaxPool2D(pool_size=<span class="number">2</span>),</span><br><span class="line">    <span class="comment"># More layers follow</span></span><br><span class="line">])</span><br></pre></td></tr></table></figure>
<h4 id="Maxpooling-具有平移不变性"><a href="#Maxpooling-具有平移不变性" class="headerlink" title="Maxpooling 具有平移不变性"></a>Maxpooling 具有平移不变性</h4><p>原理是将shape以内的最大数据作为shape的新数据，因此对于最大值所在的位置是不在乎的，因此位置不敏感了</p>
<h4 id="关于滑动窗口"><a href="#关于滑动窗口" class="headerlink" title="关于滑动窗口"></a>关于滑动窗口</h4><p>特征提取过程有：1. 使用conv层filter；2. 使用relu层detect；3. 使用maximum pooling来condense<br>其中，conv和maximum的操作都是按照滑动窗口来实现的。<br>滑动窗口大小由<code>kernel_size</code>给定，每次滑动距离由<code>strides</code>给定，使用何种类型边缘处理由<code>padding</code>给定。</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> tensorflow <span class="keyword">import</span> keras</span><br><span class="line"><span class="keyword">from</span> tensorflow.keras <span class="keyword">import</span> layers</span><br><span class="line"></span><br><span class="line">model = keras.Sequential([</span><br><span class="line">    layers.Conv2D(filters=<span class="number">64</span>,</span><br><span class="line">                  kernel_size=<span class="number">3</span>,</span><br><span class="line">                  strides=<span class="number">1</span>,</span><br><span class="line">                  padding=<span class="string">&#x27;same&#x27;</span>,</span><br><span class="line">                  activation=<span class="string">&#x27;relu&#x27;</span>),</span><br><span class="line">    layers.MaxPool2D(pool_size=<span class="number">2</span>,</span><br><span class="line">                     strides=<span class="number">1</span>,</span><br><span class="line">                     padding=<span class="string">&#x27;same&#x27;</span>)</span><br><span class="line">    <span class="comment"># More layers follow</span></span><br><span class="line">])</span><br></pre></td></tr></table></figure>
<p>为了获得更多的特征用于分类，conv的strides一般是（1，1）。而maximum pooling的strides通常为（2，2），（3，3）而不超过窗口本身。</p>
<p>边界处理使用<code>padding=&#39;valid&#39;</code>会让conv完全在图内部运行，会导致输出尺寸缩小。使用<code>padding=&#39;same&#39;</code>会在输入图像周围加上几圈0，使得输出尺寸不变。</p>
<h4 id="感受野-receptive-field"><a href="#感受野-receptive-field" class="headerlink" title="感受野 receptive field"></a>感受野 receptive field</h4><p>多层conv和maximum pooling后的一个unit对应input的区域</p>
<h3 id="数据扩增-Data-Augmentation"><a href="#数据扩增-Data-Augmentation" class="headerlink" title="数据扩增 Data Augmentation"></a>数据扩增 Data Augmentation</h3><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">from</span> tensorflow <span class="keyword">import</span> keras</span><br><span class="line"><span class="keyword">from</span> tensorflow.keras <span class="keyword">import</span> layers</span><br><span class="line"><span class="comment"># these are a new feature in TF 2.2</span></span><br><span class="line"><span class="keyword">from</span> tensorflow.keras.layers.experimental <span class="keyword">import</span> preprocessing</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">pretrained_base = tf.keras.models.load_model(</span><br><span class="line">    <span class="string">&#x27;../input/cv-course-models/cv-course-models/vgg16-pretrained-base&#x27;</span>,</span><br><span class="line">)</span><br><span class="line">pretrained_base.trainable = <span class="literal">False</span></span><br><span class="line"></span><br><span class="line">model = keras.Sequential([</span><br><span class="line">    <span class="comment"># Preprocessing</span></span><br><span class="line">    preprocessing.RandomFlip(<span class="string">&#x27;horizontal&#x27;</span>), <span class="comment"># flip left-to-right</span></span><br><span class="line">    preprocessing.RandomContrast(<span class="number">0.5</span>), <span class="comment"># contrast change by up to 50%</span></span><br><span class="line">    <span class="comment"># Base</span></span><br><span class="line">    pretrained_base,</span><br><span class="line">    <span class="comment"># Head</span></span><br><span class="line">    layers.Flatten(),</span><br><span class="line">    layers.Dense(<span class="number">6</span>, activation=<span class="string">&#x27;relu&#x27;</span>),</span><br><span class="line">    layers.Dense(<span class="number">1</span>, activation=<span class="string">&#x27;sigmoid&#x27;</span>),</span><br><span class="line">])</span><br></pre></td></tr></table></figure>


      
    </div>
    <footer class="article-footer">
      <a data-url="https://debugtheuniverse.github.io/2024/04/20/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89%E5%85%A5%E9%97%A8/" data-id="clvg47z9x000220uk6dm887i1" data-title="计算机视觉入门" class="article-share-link"><span class="fa fa-share">Teilen</span></a>
      
      
      
    </footer>
  </div>
  
</article>



  
    <article id="post-深度学习入门" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2024/04/18/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8/" class="article-date">
  <time class="dt-published" datetime="2024-04-18T10:48:46.899Z" itemprop="datePublished">2024-04-18</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="p-name article-title" href="/2024/04/18/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8/">深度学习入门</a>
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <h3 id="最简单的神经元模型"><a href="#最简单的神经元模型" class="headerlink" title="最简单的神经元模型"></a>最简单的神经元模型</h3><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line">red_wine = pd.read_csv(<span class="string">&#x27;../input/dl-course-data/red-wine.csv&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(red_wine.shape)   <span class="comment"># (1599,12)</span></span><br><span class="line"></span><br><span class="line">model = keras.Sequential([</span><br><span class="line">    layers.Dense(units=<span class="number">1</span>, input_shape=[<span class="number">11</span>]),</span><br><span class="line">])</span><br><span class="line"></span><br><span class="line">x = tf.linspace(-<span class="number">1.0</span>, <span class="number">1.0</span>, <span class="number">100</span>)</span><br><span class="line">y = model.predict(x)</span><br><span class="line"></span><br><span class="line">w, b = model.weights</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;weights\n&#123;&#125;\nBias\n&#123;&#125;&quot;</span>.<span class="built_in">format</span>(w,b))</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h3 id="深度神经元模型"><a href="#深度神经元模型" class="headerlink" title="深度神经元模型"></a>深度神经元模型</h3><h4 id="建立Sequential-Model"><a href="#建立Sequential-Model" class="headerlink" title="建立Sequential Model"></a>建立Sequential Model</h4><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> tensorflow <span class="keyword">import</span> keras</span><br><span class="line"><span class="keyword">from</span> tensorflow.keras <span class="keyword">import</span> layers</span><br><span class="line"></span><br><span class="line">model = keras.Sequential([  <span class="comment"># 所有层都放在一个list中</span></span><br><span class="line">    <span class="comment"># the hidden ReLU layers</span></span><br><span class="line">    layers.Dense(units=<span class="number">4</span>, activation=<span class="string">&#x27;relu&#x27;</span>, input_shape=[<span class="number">2</span>]),</span><br><span class="line">    layers.Dense(units=<span class="number">3</span>, activation=<span class="string">&#x27;relu&#x27;</span>),</span><br><span class="line">    <span class="comment"># the linear output layer </span></span><br><span class="line">    layers.Dense(units=<span class="number">1</span>),</span><br><span class="line">])</span><br></pre></td></tr></table></figure>
<p>把Activation单独作为层来写</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">model = keras.Sequential([</span><br><span class="line">    layers.Dense(<span class="number">32</span>, input_shape=[<span class="number">8</span>]),</span><br><span class="line">    layers.Activation(<span class="string">&#x27;relu&#x27;</span>),</span><br><span class="line">    layers.Dense(<span class="number">32</span>),</span><br><span class="line">    layers.Activation(<span class="string">&#x27;relu&#x27;</span>),</span><br><span class="line">    layers.Dense(<span class="number">1</span>),</span><br><span class="line">])</span><br></pre></td></tr></table></figure>

<h4 id="损失函数-Loss-Function"><a href="#损失函数-Loss-Function" class="headerlink" title="损失函数 Loss Function"></a>损失函数 Loss Function</h4><p>描述预测值与真实值之间的差距的一个算法，对于Regression任务的例子有MAE和MSE等</p>
<h4 id="优化器-Optimizer"><a href="#优化器-Optimizer" class="headerlink" title="优化器 Optimizer"></a>优化器 Optimizer</h4><p>调节模型权重以尽快减小Loss的算法<br>如随机梯度下降Stochastic Gradient Decent</p>
<ol>
<li>随机取样一些训练数据（数量为minibatch 或 batch），经过model得到predict</li>
<li>算出loss</li>
<li>向loss减小的方向（梯度）调节weights</li>
</ol>
<p>所有数据都过一遍model叫做一个epoch</p>
<h4 id="学习率-Learning-Rate-和-Batch-Size"><a href="#学习率-Learning-Rate-和-Batch-Size" class="headerlink" title="学习率 Learning Rate 和 Batch Size"></a>学习率 Learning Rate 和 Batch Size</h4><p>学习率和Batch Size决定SGD以多大步子和速度进行，通常不是显而易见的。<br>为此，Adam是一种自适应的SGD算法，不需要调参。</p>
<h4 id="为模型增加Loss和Optimizer"><a href="#为模型增加Loss和Optimizer" class="headerlink" title="为模型增加Loss和Optimizer"></a>为模型增加Loss和Optimizer</h4><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">model.<span class="built_in">compile</span>(</span><br><span class="line">    opertimizer=<span class="string">&#x27;adam&#x27;</span>,</span><br><span class="line">    loss=<span class="string">&#x27;mae&#x27;</span>,</span><br><span class="line">)</span><br></pre></td></tr></table></figure>

<h4 id="训练fit"><a href="#训练fit" class="headerlink" title="训练fit"></a>训练fit</h4><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">history = model.fit(</span><br><span class="line">    X_train, y_train,</span><br><span class="line">    validation_data=(X_valid, y_valid),</span><br><span class="line">    batch_size=<span class="number">256</span>,</span><br><span class="line">    epochs=<span class="number">10</span>,</span><br><span class="line">)</span><br></pre></td></tr></table></figure>

<h4 id="查看loss"><a href="#查看loss" class="headerlink" title="查看loss"></a>查看loss</h4><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"></span><br><span class="line"><span class="comment"># convert the training history to a dataframe</span></span><br><span class="line">history_df = pd.DataFrame(history.history)</span><br><span class="line"><span class="comment"># use Pandas native plot method</span></span><br><span class="line">history_df[<span class="string">&#x27;loss&#x27;</span>].plot();</span><br></pre></td></tr></table></figure>

<h3 id="Overfitting-和-Underfitting"><a href="#Overfitting-和-Underfitting" class="headerlink" title="Overfitting 和 Underfitting"></a>Overfitting 和 Underfitting</h3><p>训练数据中的信息由有用信号和噪声组成。理想模型是学习所有信号而没有噪声，但是实际上不存在。</p>
<h4 id="信号不够为Underfitting-增加模型容量Capacity，增宽增深"><a href="#信号不够为Underfitting-增加模型容量Capacity，增宽增深" class="headerlink" title="信号不够为Underfitting,增加模型容量Capacity，增宽增深"></a>信号不够为Underfitting,增加模型容量Capacity，增宽增深</h4><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">model = keras.Sequential([</span><br><span class="line">    layers.Dense(<span class="number">16</span>, activation=<span class="string">&#x27;relu&#x27;</span>),</span><br><span class="line">    layers.Dense(<span class="number">1</span>),</span><br><span class="line">])</span><br><span class="line"></span><br><span class="line">wider = keras.Sequential([</span><br><span class="line">    layers.Dense(<span class="number">32</span>, activation=<span class="string">&#x27;relu&#x27;</span>),</span><br><span class="line">    layers.Dense(<span class="number">1</span>),</span><br><span class="line">])</span><br><span class="line"></span><br><span class="line">deeper = keras.Sequential([</span><br><span class="line">    layers.Dense(<span class="number">16</span>, activation=<span class="string">&#x27;relu&#x27;</span>),</span><br><span class="line">    layers.Dense(<span class="number">16</span>, activation=<span class="string">&#x27;relu&#x27;</span>),</span><br><span class="line">    layers.Dense(<span class="number">1</span>),</span><br><span class="line">])</span><br></pre></td></tr></table></figure>
<h4 id="噪声过多Overfitting"><a href="#噪声过多Overfitting" class="headerlink" title="噪声过多Overfitting"></a>噪声过多Overfitting</h4><p>在valid Loss开始上升时Early Stop</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> tensorflow.keras.callbacks <span class="keyword">import</span> EarlyStopping</span><br><span class="line"></span><br><span class="line">early_stopping = EarlyStopping(</span><br><span class="line">    min_delta=<span class="number">0.001</span>, <span class="comment"># minimium amount of change(validation loss) to count as an improvement</span></span><br><span class="line">    patience=<span class="number">20</span>, <span class="comment"># how many epochs to wait before stopping</span></span><br><span class="line">    restore_best_weights=<span class="literal">True</span>,</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">history = model.fit(</span><br><span class="line">    X_train, y_train,</span><br><span class="line">    validation_data=(X_valid, y_valid),</span><br><span class="line">    batch_size=<span class="number">256</span>,</span><br><span class="line">    epochs=<span class="number">500</span>,</span><br><span class="line">    callbacks=[early_stopping], <span class="comment"># put your callbacks in a list  每epoch都会调用一次callback</span></span><br><span class="line">    verbose=<span class="number">0</span>,  <span class="comment"># turn off training log</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">history_df = pd.DataFrame(history.history)</span><br><span class="line">history_df.loc[:, [<span class="string">&#x27;loss&#x27;</span>, <span class="string">&#x27;val_loss&#x27;</span>]].plot();</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Minimum validation loss: &#123;&#125;&quot;</span>.<span class="built_in">format</span>(history_df[<span class="string">&#x27;val_loss&#x27;</span>].<span class="built_in">min</span>()))</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h4 id="使用Dropout减少Overfitting"><a href="#使用Dropout减少Overfitting" class="headerlink" title="使用Dropout减少Overfitting"></a>使用Dropout减少Overfitting</h4><p>Dropout让层间连接随机断开一些，直接加到你需要断开的层前面去</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">keras.Sequential([</span><br><span class="line">    <span class="comment"># ...</span></span><br><span class="line">    layers.Dropout(rate=<span class="number">0.3</span>), <span class="comment"># apply 30% dropout to the next layer</span></span><br><span class="line">    layers.Dense(<span class="number">16</span>),</span><br><span class="line">    <span class="comment"># ...</span></span><br><span class="line">])</span><br></pre></td></tr></table></figure>
<h4 id="Batch-Normalization"><a href="#Batch-Normalization" class="headerlink" title="Batch Normalization"></a>Batch Normalization</h4><p>用每一个batch数据自身的mean和deviation做normalization，还用两个可训练的参数把数据缩放到新尺度。<br>使用时适当增加网络units数量</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 直接在层后添加</span></span><br><span class="line">layers.Dense(<span class="number">16</span>, activation=<span class="string">&#x27;relu&#x27;</span>),</span><br><span class="line">layers.BatchNormalization(),</span><br><span class="line"></span><br><span class="line"><span class="comment"># 在激活函数前添加</span></span><br><span class="line">layers.Dense(<span class="number">16</span>),</span><br><span class="line">layers.BatchNormalization(),</span><br><span class="line">layers.Activation(<span class="string">&#x27;relu&#x27;</span>),</span><br><span class="line"></span><br><span class="line"><span class="comment"># 在第一层添加，相当于自适应的预处理，类似于sklearn的StandardScaler</span></span><br></pre></td></tr></table></figure>

<h3 id="二分类任务-Binary-Classification"><a href="#二分类任务-Binary-Classification" class="headerlink" title="二分类任务 Binary Classification"></a>二分类任务 Binary Classification</h3><p>分类精度是结果，但是不能作为Loss，因为变化是跳跃的。为此，使用cross-entropy，是概率分布的距离表示，预测正确的概率大则loss小。<br>为了将网络输出变为0到1之间的概率表示，就要用到sigmoid这种activation function了。</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">model.<span class="built_in">compile</span>(</span><br><span class="line">    optimizer=<span class="string">&#x27;adam&#x27;</span>,</span><br><span class="line">    loss=<span class="string">&#x27;binary_crossentropy&#x27;</span>,</span><br><span class="line">    metrics=[<span class="string">&#x27;binary_accuracy&#x27;</span>], <span class="comment"># 对于二分类 使用binary_accuracy</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure>
      
    </div>
    <footer class="article-footer">
      <a data-url="https://debugtheuniverse.github.io/2024/04/18/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8/" data-id="clv54epb900001suk16z94v78" data-title="深度学习入门" class="article-share-link"><span class="fa fa-share">Teilen</span></a>
      
      
      
    </footer>
  </div>
  
</article>



  
    <article id="post-机器学习中级" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2024/04/18/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%AD%E7%BA%A7/" class="article-date">
  <time class="dt-published" datetime="2024-04-18T00:50:57.359Z" itemprop="datePublished">2024-04-18</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="p-name article-title" href="/2024/04/18/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%AD%E7%BA%A7/">机器学习中级</a>
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <h3 id="解决丢失值"><a href="#解决丢失值" class="headerlink" title="解决丢失值"></a>解决丢失值</h3><h4 id="删除不完整列"><a href="#删除不完整列" class="headerlink" title="删除不完整列"></a>删除不完整列</h4><p>最简单直接，但是会浪费很多数据</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Get names of columns with missing values</span></span><br><span class="line">cols_with_missing = [col <span class="keyword">for</span> col <span class="keyword">in</span> X_train.columns</span><br><span class="line">                     <span class="keyword">if</span> X_train[col].isnull().<span class="built_in">any</span>()]</span><br><span class="line"></span><br><span class="line"><span class="comment"># Drop columns in training and validation data</span></span><br><span class="line">reduced_X_train = X_train.drop(cols_with_missing, axis=<span class="number">1</span>)</span><br><span class="line">reduced_X_valid = X_valid.drop(cols_with_missing, axis=<span class="number">1</span>)</span><br></pre></td></tr></table></figure>
<h4 id="插补"><a href="#插补" class="headerlink" title="插补"></a>插补</h4><p>在缺失处填上诸如列均值的方法，但要根据缺失项目的实际特征来决定是否应该这样做</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.impute <span class="keyword">import</span> SimpleImputer</span><br><span class="line"></span><br><span class="line"><span class="comment"># Imputation</span></span><br><span class="line">my_imputer = SimpleImputer()</span><br><span class="line">imputed_X_train = pd.DataFrame(my_imputer.fit_transform(X_train))</span><br><span class="line">imputed_X_valid = pd.DataFrame(my_imputer.transform(X_valid))</span><br><span class="line"></span><br><span class="line"><span class="comment"># Imputation removed column names; put them back</span></span><br><span class="line">imputed_X_train.columns = X_train.columns</span><br><span class="line">imputed_X_valid.columns = X_valid.columns</span><br></pre></td></tr></table></figure>
<h4 id="插补-拓展"><a href="#插补-拓展" class="headerlink" title="插补-拓展"></a>插补-拓展</h4><p>补上新值，新增一列布尔值表示是否为插补值</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Make copy to avoid changing original data (when imputing)</span></span><br><span class="line">X_train_plus = X_train.copy()</span><br><span class="line">X_valid_plus = X_valid.copy()</span><br><span class="line"></span><br><span class="line"><span class="comment"># Make new columns indicating what will be imputed</span></span><br><span class="line"><span class="keyword">for</span> col <span class="keyword">in</span> cols_with_missing:</span><br><span class="line">    X_train_plus[col + <span class="string">&#x27;_was_missing&#x27;</span>] = X_train_plus[col].isnull()</span><br><span class="line">    X_valid_plus[col + <span class="string">&#x27;_was_missing&#x27;</span>] = X_valid_plus[col].isnull()</span><br><span class="line"></span><br><span class="line"><span class="comment"># Imputation</span></span><br><span class="line">my_imputer = SimpleImputer()</span><br><span class="line">imputed_X_train_plus = pd.DataFrame(my_imputer.fit_transform(X_train_plus))</span><br><span class="line">imputed_X_valid_plus = pd.DataFrame(my_imputer.transform(X_valid_plus))</span><br><span class="line"></span><br><span class="line"><span class="comment"># Imputation removed column names; put them back</span></span><br><span class="line">imputed_X_train_plus.columns = X_train_plus.columns</span><br><span class="line">imputed_X_valid_plus.columns = X_valid_plus.columns</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h3 id="Categorical-分类数据"><a href="#Categorical-分类数据" class="headerlink" title="Categorical 分类数据"></a>Categorical 分类数据</h3><p>一个类别数据，例如问你有什么品牌的车，答“大众”、“丰田”、“奔驰”等</p>
<h4 id="处理类别数据的3个方法"><a href="#处理类别数据的3个方法" class="headerlink" title="处理类别数据的3个方法"></a>处理类别数据的3个方法</h4><ol>
<li><p>如果没有很重要数据，drop丢掉该变量</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Get list of categorical variables</span></span><br><span class="line">s = (X_train.dtypes == <span class="string">&#x27;object&#x27;</span>)</span><br><span class="line">object_cols = <span class="built_in">list</span>(s[s].index)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Categorical variables:&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(object_cols)</span><br><span class="line"></span><br><span class="line">drop_X_train = X_train.select_dtypes(exclude=[<span class="string">&#x27;object&#x27;</span>])</span><br><span class="line">drop_X_valid = X_valid.select_dtypes(exclude=[<span class="string">&#x27;object&#x27;</span>])</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;MAE from Approach 1 (Drop categorical variables):&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(score_dataset(drop_X_train, drop_X_valid, y_train, y_valid))</span><br></pre></td></tr></table></figure></li>
<li><p>序数编码：为每一个类别制定数字，适用于强度指标如“强”、“中”、“弱”</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> OrdinalEncoder</span><br><span class="line"></span><br><span class="line"><span class="comment"># Make copy to avoid changing original data </span></span><br><span class="line">label_X_train = X_train.copy()</span><br><span class="line">label_X_valid = X_valid.copy()</span><br><span class="line"></span><br><span class="line"><span class="comment"># Apply ordinal encoder to each column with categorical data</span></span><br><span class="line">ordinal_encoder = OrdinalEncoder()</span><br><span class="line">label_X_train[object_cols] = ordinal_encoder.fit_transform(X_train[object_cols])</span><br><span class="line">label_X_valid[object_cols] = ordinal_encoder.transform(X_valid[object_cols])</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;MAE from Approach 2 (Ordinal Encoding):&quot;</span>) </span><br><span class="line"><span class="built_in">print</span>(score_dataset(label_X_train, label_X_valid, y_train, y_valid))</span><br></pre></td></tr></table></figure>
<p>使用序数编码时，如果训练数据中的变量与测试数据变量不一样，会出现问题因此需要避免</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Categorical columns in the training data</span></span><br><span class="line">object_cols = [col <span class="keyword">for</span> col <span class="keyword">in</span> X_train.columns <span class="keyword">if</span> X_train[col].dtype == <span class="string">&quot;object&quot;</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># Columns that can be safely ordinal encoded</span></span><br><span class="line">good_label_cols = [col <span class="keyword">for</span> col <span class="keyword">in</span> object_cols <span class="keyword">if</span> </span><br><span class="line">                   <span class="built_in">set</span>(X_valid[col]).issubset(<span class="built_in">set</span>(X_train[col]))]</span><br><span class="line">        </span><br><span class="line"><span class="comment"># Problematic columns that will be dropped from the dataset</span></span><br><span class="line">bad_label_cols = <span class="built_in">list</span>(<span class="built_in">set</span>(object_cols)-<span class="built_in">set</span>(good_label_cols))</span><br><span class="line">        </span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;Categorical columns that will be ordinal encoded:&#x27;</span>, good_label_cols)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;\nCategorical columns that will be dropped from the dataset:&#x27;</span>, bad_label_cols)</span><br></pre></td></tr></table></figure>
</li>
<li><p>One-hot Encoding:创建类别数变量相同的变量，每行只有一个1，其他都是0，适用于无序类别，即名义变量nominal variables</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> OneHotEncoder</span><br><span class="line"></span><br><span class="line"><span class="comment"># Apply one-hot encoder to each column with categorical data</span></span><br><span class="line">OH_encoder = OneHotEncoder(handle_unknown=<span class="string">&#x27;ignore&#x27;</span>, sparse=<span class="literal">False</span>)</span><br><span class="line">OH_cols_train = pd.DataFrame(OH_encoder.fit_transform(X_train[object_cols]))</span><br><span class="line">OH_cols_valid = pd.DataFrame(OH_encoder.transform(X_valid[object_cols]))</span><br><span class="line"></span><br><span class="line"><span class="comment"># One-hot encoding removed index; put it back</span></span><br><span class="line">OH_cols_train.index = X_train.index</span><br><span class="line">OH_cols_valid.index = X_valid.index</span><br><span class="line"></span><br><span class="line"><span class="comment"># Remove categorical columns (will replace with one-hot encoding)</span></span><br><span class="line">num_X_train = X_train.drop(object_cols, axis=<span class="number">1</span>)</span><br><span class="line">num_X_valid = X_valid.drop(object_cols, axis=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Add one-hot encoded columns to numerical features</span></span><br><span class="line">OH_X_train = pd.concat([num_X_train, OH_cols_train], axis=<span class="number">1</span>)</span><br><span class="line">OH_X_valid = pd.concat([num_X_valid, OH_cols_valid], axis=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Ensure all columns have string type</span></span><br><span class="line">OH_X_train.columns = OH_X_train.columns.astype(<span class="built_in">str</span>)</span><br><span class="line">OH_X_valid.columns = OH_X_valid.columns.astype(<span class="built_in">str</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;MAE from Approach 3 (One-Hot Encoding):&quot;</span>) </span><br><span class="line"><span class="built_in">print</span>(score_dataset(OH_X_train, OH_X_valid, y_train, y_valid))</span><br></pre></td></tr></table></figure></li>
</ol>
<h3 id="Pipline-批处理"><a href="#Pipline-批处理" class="headerlink" title="Pipline 批处理"></a>Pipline 批处理</h3><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"></span><br><span class="line"><span class="comment"># Read the data</span></span><br><span class="line">X_full = pd.read_csv(<span class="string">&#x27;../input/train.csv&#x27;</span>, index_col=<span class="string">&#x27;Id&#x27;</span>)</span><br><span class="line">X_test_full = pd.read_csv(<span class="string">&#x27;../input/test.csv&#x27;</span>, index_col=<span class="string">&#x27;Id&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Remove rows with missing target, separate target from predictors</span></span><br><span class="line">X_full.dropna(axis=<span class="number">0</span>, subset=[<span class="string">&#x27;SalePrice&#x27;</span>], inplace=<span class="literal">True</span>)</span><br><span class="line">y = X_full.SalePrice</span><br><span class="line">X_full.drop([<span class="string">&#x27;SalePrice&#x27;</span>], axis=<span class="number">1</span>, inplace=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Break off validation set from training data</span></span><br><span class="line">X_train_full, X_valid_full, y_train, y_valid = train_test_split(X_full, y, </span><br><span class="line">                                                                train_size=<span class="number">0.8</span>, test_size=<span class="number">0.2</span>,</span><br><span class="line">                                                                random_state=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># &quot;Cardinality&quot; means the number of unique values in a column</span></span><br><span class="line"><span class="comment"># Select categorical columns with relatively low cardinality (convenient but arbitrary)</span></span><br><span class="line">categorical_cols = [cname <span class="keyword">for</span> cname <span class="keyword">in</span> X_train_full.columns <span class="keyword">if</span></span><br><span class="line">                    X_train_full[cname].nunique() &lt; <span class="number">10</span> <span class="keyword">and</span> </span><br><span class="line">                    X_train_full[cname].dtype == <span class="string">&quot;object&quot;</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># Select numerical columns</span></span><br><span class="line">numerical_cols = [cname <span class="keyword">for</span> cname <span class="keyword">in</span> X_train_full.columns <span class="keyword">if</span> </span><br><span class="line">                X_train_full[cname].dtype <span class="keyword">in</span> [<span class="string">&#x27;int64&#x27;</span>, <span class="string">&#x27;float64&#x27;</span>]]</span><br><span class="line"></span><br><span class="line"><span class="comment"># Keep selected columns only</span></span><br><span class="line">my_cols = categorical_cols + numerical_cols</span><br><span class="line">X_train = X_train_full[my_cols].copy()</span><br><span class="line">X_valid = X_valid_full[my_cols].copy()</span><br><span class="line">X_test = X_test_full[my_cols].copy()</span><br></pre></td></tr></table></figure>
<p>看下面</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.compose <span class="keyword">import</span> ColumnTransformer</span><br><span class="line"><span class="keyword">from</span> sklearn.pipeline <span class="keyword">import</span> Pipeline</span><br><span class="line"><span class="keyword">from</span> sklearn.impute <span class="keyword">import</span> SimpleImputer</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> OneHotEncoder</span><br><span class="line"><span class="keyword">from</span> sklearn.ensemble <span class="keyword">import</span> RandomForestRegressor</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> mean_absolute_error</span><br><span class="line"></span><br><span class="line"><span class="comment"># Preprocessing for numerical data</span></span><br><span class="line">numerical_transformer = SimpleImputer(strategy=<span class="string">&#x27;constant&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Preprocessing for categorical data</span></span><br><span class="line">categorical_transformer = Pipeline(steps=[</span><br><span class="line">    (<span class="string">&#x27;imputer&#x27;</span>, SimpleImputer(strategy=<span class="string">&#x27;most_frequent&#x27;</span>)),</span><br><span class="line">    (<span class="string">&#x27;onehot&#x27;</span>, OneHotEncoder(handle_unknown=<span class="string">&#x27;ignore&#x27;</span>))</span><br><span class="line">])</span><br><span class="line"></span><br><span class="line"><span class="comment"># Bundle preprocessing for numerical and categorical data</span></span><br><span class="line">preprocessor = ColumnTransformer(</span><br><span class="line">    transformers=[</span><br><span class="line">        (<span class="string">&#x27;num&#x27;</span>, numerical_transformer, numerical_cols),</span><br><span class="line">        (<span class="string">&#x27;cat&#x27;</span>, categorical_transformer, categorical_cols)</span><br><span class="line">    ])</span><br><span class="line"></span><br><span class="line"><span class="comment"># Define model</span></span><br><span class="line">model = RandomForestRegressor(n_estimators=<span class="number">100</span>, random_state=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Bundle preprocessing and modeling code in a pipeline</span></span><br><span class="line">clf = Pipeline(steps=[(<span class="string">&#x27;preprocessor&#x27;</span>, preprocessor),</span><br><span class="line">                      (<span class="string">&#x27;model&#x27;</span>, model)</span><br><span class="line">                     ])</span><br><span class="line"></span><br><span class="line"><span class="comment"># Preprocessing of training data, fit model </span></span><br><span class="line">clf.fit(X_train, y_train)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Preprocessing of validation data, get predictions</span></span><br><span class="line">preds = clf.predict(X_valid)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;MAE:&#x27;</span>, mean_absolute_error(y_valid, preds))</span><br></pre></td></tr></table></figure>

<h3 id="data-leakage"><a href="#data-leakage" class="headerlink" title="data leakage"></a>data leakage</h3><p>data leakage是训练时包括目标的信息，在预测时却没有该项信息，从而在训练集和验证集表现很好，但是在实际应用或者测试集表现不好。<br>target leakage: 以目标值为因素进行变化的任何变量都应该舍弃,如判断是否感冒，就应该把吃感冒药这种变量舍去<br>Train-Test 污染：人会根据测试结果调整预处理方式</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://debugtheuniverse.github.io/2024/04/18/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%AD%E7%BA%A7/" data-id="clv54c5ys0000okuk5xithf5s" data-title="机器学习中级" class="article-share-link"><span class="fa fa-share">Teilen</span></a>
      
      
      
    </footer>
  </div>
  
</article>



  
    <article id="post-Pandas入门" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2024/04/17/Pandas%E5%85%A5%E9%97%A8/" class="article-date">
  <time class="dt-published" datetime="2024-04-17T04:06:34.879Z" itemprop="datePublished">2024-04-17</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="p-name article-title" href="/2024/04/17/Pandas%E5%85%A5%E9%97%A8/">Pandas入门</a>
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <h4 id="导入库"><a href="#导入库" class="headerlink" title="导入库"></a>导入库</h4><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br></pre></td></tr></table></figure>
<h4 id="创建数据"><a href="#创建数据" class="headerlink" title="创建数据"></a>创建数据</h4><p>在Pandas中有两种核心数据：<code>DataFrame</code>和<code>Series</code></p>
<h4 id="创建DataFrame"><a href="#创建DataFrame" class="headerlink" title="创建DataFrame"></a>创建DataFrame</h4><p><code>DataFrame</code>是一个表格，包含多个独立条目的序列，每个条目下面是一列数据。每一行叫record</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">pd.DataFrame(&#123;<span class="string">&#x27;Yes&#x27;</span>:[<span class="number">50</span>,<span class="number">21</span>], <span class="string">&#x27;No&#x27;</span>:[<span class="number">131</span>,<span class="number">2</span>]&#125;)</span><br><span class="line">pd.DataFrame(&#123;<span class="string">&#x27;Bob&#x27;</span>: [<span class="string">&#x27;I liked it.&#x27;</span>, <span class="string">&#x27;It was awful.&#x27;</span>], <span class="string">&#x27;Sue&#x27;</span>: [<span class="string">&#x27;Pretty good.&#x27;</span>, <span class="string">&#x27;Bland.&#x27;</span>]&#125;)</span><br></pre></td></tr></table></figure>

<p>行标被称为<code>Index</code></p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">pd.DataFrame(&#123;<span class="string">&#x27;Bob&#x27;</span>: [<span class="string">&#x27;I liked it.&#x27;</span>, <span class="string">&#x27;It was awful.&#x27;</span>], </span><br><span class="line">              <span class="string">&#x27;Sue&#x27;</span>: [<span class="string">&#x27;Pretty good.&#x27;</span>, <span class="string">&#x27;Bland.&#x27;</span>]&#125;,</span><br><span class="line">             index=[<span class="string">&#x27;Product A&#x27;</span>, <span class="string">&#x27;Product B&#x27;</span>])</span><br></pre></td></tr></table></figure>

<h4 id="创建Series"><a href="#创建Series" class="headerlink" title="创建Series"></a>创建Series</h4><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pd.Series([<span class="number">30</span>, <span class="number">35</span>, <span class="number">40</span>], index=[<span class="string">&#x27;2015 Sales&#x27;</span>, <span class="string">&#x27;2016 Sales&#x27;</span>, <span class="string">&#x27;2017 Sales&#x27;</span>], name=<span class="string">&#x27;Product A&#x27;</span>)</span><br></pre></td></tr></table></figure>

<h4 id="读取数据"><a href="#读取数据" class="headerlink" title="读取数据"></a>读取数据</h4><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">wine_reviews = pd.read_csv(<span class="string">&quot;filename.csv&quot;</span>)</span><br><span class="line">wine_reviews = pd.read_csv(<span class="string">&quot;filename.csv&quot;</span>,index_col=<span class="number">0</span>) <span class="comment"># 使用Excel文档中已有的index</span></span><br></pre></td></tr></table></figure>

<h4 id="观察数据"><a href="#观察数据" class="headerlink" title="观察数据"></a>观察数据</h4><p>看形状、看头看尾</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">wine_reviews.shape</span><br><span class="line">wine_reviews.head()</span><br><span class="line">wine_reviews.tail()</span><br></pre></td></tr></table></figure>

<h4 id="保存数据"><a href="#保存数据" class="headerlink" title="保存数据"></a>保存数据</h4><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">wine_reviews.to_csv(<span class="string">&#x27;savefilename.csv&#x27;</span>)</span><br></pre></td></tr></table></figure>

<h4 id="索引"><a href="#索引" class="headerlink" title="索引"></a>索引</h4><p>基本索引方式</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">reviews.country</span><br><span class="line">reviews[<span class="string">&#x27;country&#x27;</span>]</span><br></pre></td></tr></table></figure>
<p>pandas中有<code>loc</code>和<code>iloc</code>方法，都是先行row后列column，与基本方式相反</p>
<h4 id="基于index的索引"><a href="#基于index的索引" class="headerlink" title="基于index的索引"></a>基于index的索引</h4><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">reviews.iloc[:, <span class="number">0</span>] <span class="comment"># 获取第一列</span></span><br><span class="line">reviews.iloc[-<span class="number">5</span>:] <span class="comment"># 最后5行</span></span><br></pre></td></tr></table></figure>

<h4 id="基于标签的索引"><a href="#基于标签的索引" class="headerlink" title="基于标签的索引"></a>基于标签的索引</h4><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">reviews.loc[<span class="number">0</span>, <span class="string">&#x27;country&#x27;</span>] <span class="comment"># 获取第一行，country列的元素</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>使用<code>loc</code>索引0：10就是0,…,10<br>使用<code>iloc</code>索引0：10就是0,…,9</p>
<h4 id="基于标签判断的缩影"><a href="#基于标签判断的缩影" class="headerlink" title="基于标签判断的缩影"></a>基于标签判断的缩影</h4><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">italian_wines = reviews[reviews.country == <span class="string">&#x27;Italy&#x27;</span>]</span><br><span class="line">top_oceania_wines = reviews.loc[(reviews.country.isin([<span class="string">&#x27;Australia&#x27;</span>,<span class="string">&#x27;New Zealand&#x27;</span>])) &amp; (reviews.points&gt;=<span class="number">95</span>)]</span><br></pre></td></tr></table></figure>

<h4 id="不重复元素"><a href="#不重复元素" class="headerlink" title="不重复元素"></a>不重复元素</h4><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">reviews.country.unique()</span><br></pre></td></tr></table></figure>

<h4 id="元素计数"><a href="#元素计数" class="headerlink" title="元素计数"></a>元素计数</h4><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">reviews.country.value_count()</span><br></pre></td></tr></table></figure>

<h4 id="使用map"><a href="#使用map" class="headerlink" title="使用map()"></a>使用map()</h4><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">reviews.points.<span class="built_in">map</span>(<span class="keyword">lambda</span> p: p - review_points_mean)</span><br></pre></td></tr></table></figure>
<p>传给<code>map()</code>的function每次接收Series中的一个值，返回一个新的Series包含所有被function转换后的值</p>
<p>同样的操作可以用<code>apply()</code>实现</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">remean_points</span>(<span class="params">row</span>):</span><br><span class="line">    row.points = row.points - review_points_mean</span><br><span class="line">    <span class="keyword">return</span> row</span><br><span class="line"></span><br><span class="line">reviews.apply(remean_points, axis=<span class="string">&#x27;columns&#x27;</span>) <span class="comment"># axis=index 时则应用函数到每列</span></span><br></pre></td></tr></table></figure>

<h4 id="idxmax"><a href="#idxmax" class="headerlink" title="idxmax()"></a>idxmax()</h4><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">bargain_idx = (reviews.points / reviews.price).idxmax()</span><br><span class="line">bargain_wine = reviews.loc[bargain_idx,<span class="string">&#x27;title&#x27;</span>]</span><br></pre></td></tr></table></figure>

<h4 id="grouping-和-sorting"><a href="#grouping-和-sorting" class="headerlink" title="grouping 和 sorting"></a>grouping 和 sorting</h4><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">reviews.groupby(<span class="string">&#x27;points&#x27;</span>).points.count()</span><br><span class="line">reviews.groupby(<span class="string">&#x27;winery&#x27;</span>).apply(<span class="keyword">lambda</span> df: df.title.iloc[<span class="number">0</span>])</span><br></pre></td></tr></table></figure>
<p><code>agg()</code>函数可以实现同时运行多种函数</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">reviews.groupby([<span class="string">&#x27;country&#x27;</span>]).price.agg([<span class="built_in">len</span>, <span class="built_in">min</span>, <span class="built_in">max</span>])</span><br></pre></td></tr></table></figure>

<h4 id="多索引"><a href="#多索引" class="headerlink" title="多索引"></a>多索引</h4><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">countries_reviewed = reviews.groupby([<span class="string">&#x27;country&#x27;</span>, <span class="string">&#x27;province&#x27;</span>]).description.agg([<span class="built_in">len</span>])</span><br></pre></td></tr></table></figure>
<h4 id="复原"><a href="#复原" class="headerlink" title="复原"></a>复原</h4><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">countries_reviewed.reset_index()</span><br></pre></td></tr></table></figure>

<h4 id="Sorting"><a href="#Sorting" class="headerlink" title="Sorting"></a>Sorting</h4><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">countries_reviewed = countries_reviewed.reset_index()</span><br><span class="line">countries_reviewed.sort_values(by=<span class="string">&#x27;len&#x27;</span>)  <span class="comment"># 默认ascending = True</span></span><br><span class="line"><span class="comment"># 使用index排序</span></span><br><span class="line">countries_reviewed.sort_index()</span><br><span class="line"><span class="comment"># 使用两个同时排序</span></span><br><span class="line">countries_reviewed.sort_values(by=[<span class="string">&#x27;country&#x27;</span>, <span class="string">&#x27;len&#x27;</span>])</span><br></pre></td></tr></table></figure>

<h4 id="计数"><a href="#计数" class="headerlink" title="计数"></a>计数</h4><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">reviews_written = reviews.groupby(<span class="string">&#x27;taster_twitter_handle&#x27;</span>).size()</span><br><span class="line"></span><br><span class="line">reviews_written = reviews.groupby(<span class="string">&#x27;taster_twitter_handle&#x27;</span>).taster_twitter_handle.count()</span><br></pre></td></tr></table></figure>

<h4 id="数据类型和缺失值"><a href="#数据类型和缺失值" class="headerlink" title="数据类型和缺失值"></a>数据类型和缺失值</h4><h4 id="数据类型"><a href="#数据类型" class="headerlink" title="数据类型"></a>数据类型</h4><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">reviews.price.dtype</span><br><span class="line"><span class="comment"># 更改类型</span></span><br><span class="line">reviews.points.astype(<span class="string">&#x27;float64&#x27;</span>)</span><br></pre></td></tr></table></figure>

<p>丢失值<code>NaN</code>，类型是<code>float64</code></p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">reviews[pd.isnull(reviews.country)]</span><br></pre></td></tr></table></figure>

<p>替换丢失值是常见操作，例如替换为<code>Unknown</code></p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">reviews.region_2.fillna(<span class="string">&#x27;Unknown&#x27;</span>)</span><br></pre></td></tr></table></figure>

<h4 id="替换正常值"><a href="#替换正常值" class="headerlink" title="替换正常值"></a>替换正常值</h4><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">reviews.taster_twitter_handle.replace(<span class="string">&quot;@kerinokeefe&quot;</span>, <span class="string">&quot;@kerino&quot;</span>)</span><br></pre></td></tr></table></figure>

<h4 id="重命名"><a href="#重命名" class="headerlink" title="重命名"></a>重命名</h4><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 给column重命名</span></span><br><span class="line">reviews.rename(columns=&#123;<span class="string">&#x27;points&#x27;</span>: <span class="string">&#x27;score&#x27;</span>&#125;)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 给index重命名</span></span><br><span class="line">reviews.rename(index=&#123;<span class="number">0</span>:<span class="string">&#x27;FirstEntry&#x27;</span>,<span class="number">1</span>:<span class="string">&#x27;SecondEntry&#x27;</span>&#125;)</span><br></pre></td></tr></table></figure>

<h4 id="行和列都可以有自己的名字属性"><a href="#行和列都可以有自己的名字属性" class="headerlink" title="行和列都可以有自己的名字属性"></a>行和列都可以有自己的名字属性</h4><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">reviews.rename_axis(<span class="string">&quot;wines&quot;</span>, axis=<span class="string">&#x27;rows&#x27;</span>).rename_axis(<span class="string">&quot;fields&quot;</span>, axis=<span class="string">&#x27;columns&#x27;</span>)</span><br></pre></td></tr></table></figure>

<h4 id="组合数据的三种方式"><a href="#组合数据的三种方式" class="headerlink" title="组合数据的三种方式"></a>组合数据的三种方式</h4><p><code>concat()</code>,<code>join()</code>,<code>merge()</code>，后者与join类似</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># concat() 组合具有相同column的数据</span></span><br><span class="line">canadian_youtube = pd.read_csv(<span class="string">&quot;../input/youtube-new/CAvideos.csv&quot;</span>)</span><br><span class="line">british_youtube = pd.read_csv(<span class="string">&quot;../input/youtube-new/GBvideos.csv&quot;</span>)</span><br><span class="line"></span><br><span class="line">pd.concat([canadian_youtube, british_youtube])</span><br><span class="line"></span><br><span class="line"><span class="comment"># join() 组合具有相同index的数据</span></span><br><span class="line">left = canadian_youtube.set_index([<span class="string">&#x27;title&#x27;</span>, <span class="string">&#x27;trending_date&#x27;</span>])</span><br><span class="line">right = british_youtube.set_index([<span class="string">&#x27;title&#x27;</span>, <span class="string">&#x27;trending_date&#x27;</span>])</span><br><span class="line"></span><br><span class="line">left.join(right, lsuffix=<span class="string">&#x27;_CAN&#x27;</span>, rsuffix=<span class="string">&#x27;_UK&#x27;</span>) <span class="comment"># 后两个参数是后缀必须</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>
      
    </div>
    <footer class="article-footer">
      <a data-url="https://debugtheuniverse.github.io/2024/04/17/Pandas%E5%85%A5%E9%97%A8/" data-id="clv3quf8y0001fcukb6ai7rzg" data-title="Pandas入门" class="article-share-link"><span class="fa fa-share">Teilen</span></a>
      
      
      
    </footer>
  </div>
  
</article>



  
    <article id="post-机器学习入门" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2024/04/16/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8/" class="article-date">
  <time class="dt-published" datetime="2024-04-16T09:54:31.667Z" itemprop="datePublished">2024-04-16</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="p-name article-title" href="/2024/04/16/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8/">机器学习入门</a>
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <h4 id="使用Pandas打开csv数据"><a href="#使用Pandas打开csv数据" class="headerlink" title="使用Pandas打开csv数据"></a>使用Pandas打开csv数据</h4><p>Pandas中数据是DataFrame，保存的数据类似一个Excel的sheet，或者SQL中的一个table</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="comment"># save filepath to variable for easier access</span></span><br><span class="line">melbourne_file_path = <span class="string">&#x27;../input/melbourne-housing-snapshot/melb_data.csv&#x27;</span></span><br><span class="line"><span class="comment"># read the data and store data in DataFrame titled melbourne_data</span></span><br><span class="line">melbourne_data = pd.read_csv(melbourne_file_path) </span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h4 id="了解数据"><a href="#了解数据" class="headerlink" title="了解数据"></a>了解数据</h4><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># print a summary of the data in Melbourne data</span></span><br><span class="line">melbourne_data.describe()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 显示所有列索引</span></span><br><span class="line"><span class="built_in">print</span>(melbourne_data.columns)</span><br></pre></td></tr></table></figure>

<h4 id="设定Target"><a href="#设定Target" class="headerlink" title="设定Target"></a>设定Target</h4><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">y = melbourne_data[<span class="string">&#x27;SalePrice&#x27;</span>]</span><br></pre></td></tr></table></figure>

<h4 id="设定Input"><a href="#设定Input" class="headerlink" title="设定Input"></a>设定Input</h4><p>在所有列索引中选择需要的作为输入特征，如</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">feature_names = [<span class="string">&#x27;LotArea&#x27;</span>,<span class="string">&#x27;YearBuilt&#x27;</span>,<span class="string">&#x27;1stFlrSF&#x27;</span>,<span class="string">&#x27;2ndFlrSF&#x27;</span>,<span class="string">&#x27;FullBath&#x27;</span>,<span class="string">&#x27;BedroomAbvGr&#x27;</span>,<span class="string">&#x27;TotRmsAbvGrd&#x27;</span>]</span><br><span class="line">X = melbourne_data[feature_names]</span><br><span class="line"><span class="comment"># 观察输入数据</span></span><br><span class="line"><span class="built_in">print</span>(X.describe())</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h4 id="数据划分-train-X、train-y、val-X、val-y"><a href="#数据划分-train-X、train-y、val-X、val-y" class="headerlink" title="数据划分 train_X、train_y、val_X、val_y"></a>数据划分 train_X、train_y、val_X、val_y</h4><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line">train_X, train_y, val_X, val_y = train_test_split(X,y,random_state=<span class="number">1</span>)</span><br></pre></td></tr></table></figure>

<h4 id="配置和拟合Model"><a href="#配置和拟合Model" class="headerlink" title="配置和拟合Model"></a>配置和拟合Model</h4><p>以<code>DecisionTreeRegressor</code>为例</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.tree <span class="keyword">import</span> DecisionTreeRegressor</span><br><span class="line">melbourne_model = DecisionTreeRegressor(random_state=<span class="number">1</span>)</span><br><span class="line">melbourne_model.fit(train_X, train_y)</span><br></pre></td></tr></table></figure>

<h4 id="做预测"><a href="#做预测" class="headerlink" title="做预测"></a>做预测</h4><p>输入X为例</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">predictions = melbourne_model.predict(val_X)</span><br></pre></td></tr></table></figure>

<h4 id="模型验证"><a href="#模型验证" class="headerlink" title="模型验证"></a>模型验证</h4><p>以Mean Absolute Error（MAE）为例</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> mean_absolute_error</span><br><span class="line">val_mae = mean_absolute_error(melbourne_model.predict(val_X), val_y)</span><br></pre></td></tr></table></figure>

<h4 id="调参时候的操作方法"><a href="#调参时候的操作方法" class="headerlink" title="调参时候的操作方法"></a>调参时候的操作方法</h4><p>以寻找最大叶节点为例</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">get_mae</span>(<span class="params">max_leaf_nodes, train_X, val_X, train_y, val_y</span>):</span><br><span class="line">    model = DecisionTreeRegressor(max_leaf_nodes=max_leaf_nodes, random_state=<span class="number">0</span>)</span><br><span class="line">    model.fit(train_X, train_y)</span><br><span class="line">    preds_val = model.predict(val_X)</span><br><span class="line">    mae = mean_absolute_error(val_y, preds_val)</span><br><span class="line">    <span class="keyword">return</span>(mae)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用不同的最大叶节点</span></span><br><span class="line">candidate_max_leaf_nodes = [<span class="number">5</span>, <span class="number">25</span>, <span class="number">50</span>, <span class="number">100</span>, <span class="number">250</span>, <span class="number">500</span>]</span><br><span class="line"><span class="comment"># Store the best value of max_leaf_nodes (it will be either 5, 25, 50, 100, 250 or 500)</span></span><br><span class="line">maes = [get_mae(mln,train_X, val_X, train_y, val_y) <span class="keyword">for</span> mln <span class="keyword">in</span> candidate_max_leaf_nodes]</span><br><span class="line">best_tree_size = candidate_max_leaf_nodes[maes.index(<span class="built_in">min</span>(maes))]</span><br><span class="line"><span class="built_in">print</span>(best_tree_size)</span><br></pre></td></tr></table></figure>

<h4 id="使用全部data拟合Model"><a href="#使用全部data拟合Model" class="headerlink" title="使用全部data拟合Model"></a>使用全部data拟合Model</h4><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 基于前述最佳参数建立模型，如最大叶节点100</span></span><br><span class="line">final_model = DecisionTreeRegressor(max_leaf_nodes=<span class="number">100</span>)</span><br><span class="line"><span class="comment"># 使用所有数据参与训练</span></span><br><span class="line">final_model.fit(X,y)</span><br></pre></td></tr></table></figure>

<h4 id="使用其他算法"><a href="#使用其他算法" class="headerlink" title="使用其他算法"></a>使用其他算法</h4><p>随机森林Random Forest 是比决策树更容易得到好结果的模型</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.ensemble <span class="keyword">import</span> RandomForestRegressor</span><br><span class="line"><span class="keyword">from</span> sklearn.metric <span class="keyword">import</span> mean_absolute_error</span><br><span class="line"></span><br><span class="line"><span class="comment"># Define the model. Set random_state to 1</span></span><br><span class="line">rf_model = RandomForestRegressor(random_state=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># fit your model</span></span><br><span class="line">rf_model.fit(train_X, train_y)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Calculate the mean absolute error of your Random Forest model on the validation data</span></span><br><span class="line">rf_val_mae = mean_absolute_error(rf_model.predict(val_X),val_y)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Validation MAE for Random Forest Model: &#123;&#125;&quot;</span>.<span class="built_in">format</span>(rf_val_mae))</span><br></pre></td></tr></table></figure>

<h4 id="在kaggle打比赛"><a href="#在kaggle打比赛" class="headerlink" title="在kaggle打比赛"></a>在kaggle打比赛</h4><p>首先需要加入比赛<code>join competition</code><br>然后运行后在<code>kaggle/working</code>中生成<code>submission.csv</code><br>点击<code>submit</code>即可</p>
<h4 id="继续折腾"><a href="#继续折腾" class="headerlink" title="继续折腾"></a>继续折腾</h4><p>试验是最好的手段，尝试选用不同的features</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://debugtheuniverse.github.io/2024/04/16/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8/" data-id="clv54jjvg0000rkuk7fvbb8rd" data-title="机器学习入门" class="article-share-link"><span class="fa fa-share">Teilen</span></a>
      
      
      
    </footer>
  </div>
  
</article>



  
    <article id="post-微信运动自动点赞" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2024/04/12/%E5%BE%AE%E4%BF%A1%E8%BF%90%E5%8A%A8%E8%87%AA%E5%8A%A8%E7%82%B9%E8%B5%9E/" class="article-date">
  <time class="dt-published" datetime="2024-04-12T10:48:37.191Z" itemprop="datePublished">2024-04-12</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="p-name article-title" href="/2024/04/12/%E5%BE%AE%E4%BF%A1%E8%BF%90%E5%8A%A8%E8%87%AA%E5%8A%A8%E7%82%B9%E8%B5%9E/">微信运动自动点赞</a>
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <h4 id="思路"><a href="#思路" class="headerlink" title="思路"></a>思路</h4><p>通过USB调试在电脑显示并可操作手机屏幕<br>使用pyautogui获取屏幕图像<br>使用opencv处理和模板匹配，识别需要点击的区域<br>使用pyautogui点击，并滚动下一页</p>
<h4 id="方法"><a href="#方法" class="headerlink" title="方法"></a>方法</h4><h5 id="安卓手机"><a href="#安卓手机" class="headerlink" title="安卓手机"></a>安卓手机</h5><ol>
<li>激活开发者模式</li>
<li>在开发者选项中勾选“允许USB调试”</li>
<li>用USB线缆连接电脑</li>
</ol>
<h5 id="电脑"><a href="#电脑" class="headerlink" title="电脑"></a>电脑</h5><ol>
<li>打开软件scrcpy.exe，正常可看到并操控手机屏幕，软件官网<a target="_blank" rel="noopener" href="https://scrcpy.org/">scrcpy</a></li>
<li>将窗口调整到固定位置，使用截图工具将待点击的心形图截图保存为<code>heart.jpg</code></li>
<li>在同一文件夹创建并运行Python脚本如下</li>
</ol>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pyautogui</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> cv2 <span class="keyword">as</span> cv</span><br><span class="line"></span><br><span class="line"><span class="comment"># 设定点击的间隔时长</span></span><br><span class="line">pyautogui.PAUSE = <span class="number">0.02</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">match_click</span>(<span class="params">image, templ</span>):</span><br><span class="line">    <span class="keyword">assert</span> image <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>, <span class="string">&quot;file could not be read, check with os.path.exists()&quot;</span></span><br><span class="line">    <span class="comment"># 二值化操作，选用了阈值240，如果发现完全不工作，在0-255之间调整一下</span></span><br><span class="line">    ret,img = cv.threshold(image,<span class="number">240</span>,<span class="number">255</span>,cv.THRESH_BINARY)</span><br><span class="line">    <span class="comment"># 模板图片，保存好的</span></span><br><span class="line">    template = cv.imread(templ,cv.IMREAD_GRAYSCALE)</span><br><span class="line">    <span class="keyword">assert</span> template <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>, <span class="string">&quot;file could not be read, check with os.path.exists()&quot;</span></span><br><span class="line">    h, w = template.shape[:<span class="number">2</span>]</span><br><span class="line">    <span class="comment"># 匹配模板</span></span><br><span class="line">    res = cv.matchTemplate(img, template, cv.TM_CCOEFF_NORMED)</span><br><span class="line">    <span class="comment"># 只保留高置信度结果</span></span><br><span class="line">    threshold = <span class="number">0.8</span></span><br><span class="line">    loc = np.where( res &gt;= threshold)</span><br><span class="line">    <span class="keyword">for</span> pt <span class="keyword">in</span> <span class="built_in">zip</span>(*loc[::-<span class="number">1</span>]):</span><br><span class="line">        <span class="comment"># 点击</span></span><br><span class="line">        pyautogui.click(pt[<span class="number">0</span>],pt[<span class="number">1</span>], button=<span class="string">&#x27;left&#x27;</span>)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">12</span>):</span><br><span class="line">        pyautogui.scroll(-<span class="number">100</span>)</span><br><span class="line">        time.sleep(<span class="number">0.2</span>)</span><br><span class="line"></span><br><span class="line">i = <span class="number">0</span></span><br><span class="line">time.sleep(<span class="number">1</span>)</span><br><span class="line"><span class="keyword">while</span>(<span class="literal">True</span>):</span><br><span class="line">   </span><br><span class="line"></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        <span class="comment"># 获取截屏图像</span></span><br><span class="line">        img = pyautogui.screenshot()</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 从PIL转OpenCV</span></span><br><span class="line">        img = cv.cvtColor(np.asarray(img),cv.COLOR_RGB2GRAY) </span><br><span class="line">        </span><br><span class="line">        match_click(img, <span class="string">&#x27;heart.jpg&#x27;</span>)</span><br><span class="line">      </span><br><span class="line">        i +=<span class="number">1</span></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;第&#123;&#125;页&#x27;</span>.<span class="built_in">format</span>(i))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">except</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;没有发现目标&quot;</span>)</span><br><span class="line">        <span class="keyword">break</span></span><br></pre></td></tr></table></figure>

<h4 id="存在的Bug"><a href="#存在的Bug" class="headerlink" title="存在的Bug"></a>存在的Bug</h4><ol>
<li>不能避免给自己点赞，导致进入自己的微信运动主页而中断。</li>
</ol>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://debugtheuniverse.github.io/2024/04/12/%E5%BE%AE%E4%BF%A1%E8%BF%90%E5%8A%A8%E8%87%AA%E5%8A%A8%E7%82%B9%E8%B5%9E/" data-id="cluwkgrpc0000r8ukf3jz0ly4" data-title="微信运动自动点赞" class="article-share-link"><span class="fa fa-share">Teilen</span></a>
      
      
      
    </footer>
  </div>
  
</article>



  
    <article id="post-OpenCV 特征匹配" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2024/04/01/OpenCV%20%E7%89%B9%E5%BE%81%E5%8C%B9%E9%85%8D/" class="article-date">
  <time class="dt-published" datetime="2024-04-01T07:04:04.768Z" itemprop="datePublished">2024-04-01</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="p-name article-title" href="/2024/04/01/OpenCV%20%E7%89%B9%E5%BE%81%E5%8C%B9%E9%85%8D/">OpenCV 特征匹配</a>
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <h4 id="1-暴力匹配"><a href="#1-暴力匹配" class="headerlink" title="1. 暴力匹配"></a>1. 暴力匹配</h4><p>暴力匹配使用一些距离计算两组特征描述之间的匹配度</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> cv2 <span class="keyword">as</span> cv</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"> </span><br><span class="line">img1 = cv.imread(<span class="string">&#x27;images/box.png&#x27;</span>,cv.IMREAD_GRAYSCALE) <span class="comment"># queryImage</span></span><br><span class="line">img2 = cv.imread(<span class="string">&#x27;images/box_in_scene.png&#x27;</span>,cv.IMREAD_GRAYSCALE) <span class="comment"># trainImage</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用 ORB </span></span><br><span class="line"><span class="comment"># Initiate ORB detector</span></span><br><span class="line">orb = cv.ORB_create()</span><br><span class="line"> </span><br><span class="line"><span class="comment"># find the keypoints and descriptors with ORB</span></span><br><span class="line">kp1, des1 = orb.detectAndCompute(img1,<span class="literal">None</span>)</span><br><span class="line">kp2, des2 = orb.detectAndCompute(img2,<span class="literal">None</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># create BFMatcher object</span></span><br><span class="line">bf = cv.BFMatcher(cv.NORM_HAMMING, crossCheck=<span class="literal">True</span>)</span><br><span class="line"> </span><br><span class="line"><span class="comment"># Match descriptors.</span></span><br><span class="line">matches = bf.<span class="keyword">match</span>(des1,des2)</span><br><span class="line"> </span><br><span class="line"><span class="comment"># Sort them in the order of their distance.</span></span><br><span class="line">matches = <span class="built_in">sorted</span>(matches, key = <span class="keyword">lambda</span> x:x.distance)</span><br><span class="line"> </span><br><span class="line"><span class="comment"># Draw first 10 matches.</span></span><br><span class="line">img3 = cv.drawMatches(img1,kp1,img2,kp2,matches[:<span class="number">15</span>],<span class="literal">None</span>,flags=cv.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS)</span><br><span class="line"> </span><br><span class="line">plt.imshow(img3),plt.title(<span class="string">&#x27;ORB&#x27;</span>),plt.show()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用 SIFT</span></span><br><span class="line"><span class="comment"># Initiate SIFT detector</span></span><br><span class="line">sift = cv.SIFT_create()</span><br><span class="line"> </span><br><span class="line"><span class="comment"># find the keypoints and descriptors with SIFT</span></span><br><span class="line">kp1, des1 = sift.detectAndCompute(img1,<span class="literal">None</span>)</span><br><span class="line">kp2, des2 = sift.detectAndCompute(img2,<span class="literal">None</span>)</span><br><span class="line"> </span><br><span class="line"><span class="comment"># BFMatcher with default params</span></span><br><span class="line">bf = cv.BFMatcher()</span><br><span class="line">matches = bf.knnMatch(des1,des2,k=<span class="number">2</span>)</span><br><span class="line"> </span><br><span class="line"><span class="comment"># Apply ratio test</span></span><br><span class="line">good = []</span><br><span class="line"><span class="keyword">for</span> m,n <span class="keyword">in</span> matches:</span><br><span class="line"> <span class="keyword">if</span> m.distance &lt; <span class="number">0.35</span>*n.distance:</span><br><span class="line">    good.append([m])</span><br><span class="line"> </span><br><span class="line"><span class="comment"># cv.drawMatchesKnn expects list of lists as matches.</span></span><br><span class="line">img3 = cv.drawMatchesKnn(img1,kp1,img2,kp2,good,<span class="literal">None</span>,flags=cv.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS)</span><br><span class="line"> </span><br><span class="line">plt.imshow(img3),plt.title(<span class="string">&#x27;SIFT&#x27;</span>),plt.show()</span><br></pre></td></tr></table></figure>

<h4 id="2-基于FLANN的匹配"><a href="#2-基于FLANN的匹配" class="headerlink" title="2. 基于FLANN的匹配"></a>2. 基于FLANN的匹配</h4><p>FLANN是近似最近邻的快速库.包含了针对大型高维特征快速最近邻搜索优化的算法集.在大数据集上比BFMatcher更好.<br>使用FLANN,需要传入索引字典<code>IndexParams</code>描述所用算法及其参数.如需要使用SIFT&#x2F;SURF等,传入如下内容</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">FLANN_INDEX_KDTREE = <span class="number">1</span></span><br><span class="line">index_params = <span class="built_in">dict</span>(algorithm = FLANN_INDEX_KDTREE, trees = <span class="number">5</span>)</span><br></pre></td></tr></table></figure>
<p>而使用ORB,使用如下,参数要自己调整,文档中建议的不一定最符合实际使用</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">FLANN_INDEX_LSH = <span class="number">6</span></span><br><span class="line">index_params= <span class="built_in">dict</span>(algorithm = FLANN_INDEX_LSH,</span><br><span class="line">    table_number = <span class="number">6</span>, <span class="comment"># 12</span></span><br><span class="line">    key_size = <span class="number">12</span>, <span class="comment"># 20</span></span><br><span class="line">    multi_probe_level = <span class="number">1</span>) <span class="comment">#2</span></span><br></pre></td></tr></table></figure>
<p>第二个字典是SearchParams,定义应该递归遍历索引中的树的次数,这个值越高精度越高,但是同样会消耗更多的时间</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> cv2 <span class="keyword">as</span> cv</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"> </span><br><span class="line">img1 = cv.imread(<span class="string">&#x27;images/box.png&#x27;</span>,cv.IMREAD_GRAYSCALE) <span class="comment"># queryImage</span></span><br><span class="line">img2 = cv.imread(<span class="string">&#x27;images/box_in_scene.png&#x27;</span>,cv.IMREAD_GRAYSCALE) <span class="comment"># trainImage</span></span><br><span class="line"> </span><br><span class="line"><span class="comment"># Initiate SIFT detector</span></span><br><span class="line">sift = cv.SIFT_create()</span><br><span class="line"> </span><br><span class="line"><span class="comment"># find the keypoints and descriptors with SIFT</span></span><br><span class="line">kp1, des1 = sift.detectAndCompute(img1,<span class="literal">None</span>)</span><br><span class="line">kp2, des2 = sift.detectAndCompute(img2,<span class="literal">None</span>)</span><br><span class="line"> </span><br><span class="line"><span class="comment"># FLANN parameters</span></span><br><span class="line">FLANN_INDEX_KDTREE = <span class="number">1</span></span><br><span class="line">index_params = <span class="built_in">dict</span>(algorithm = FLANN_INDEX_KDTREE, trees = <span class="number">5</span>)</span><br><span class="line">search_params = <span class="built_in">dict</span>(checks=<span class="number">50</span>) <span class="comment"># or pass empty dictionary</span></span><br><span class="line"> </span><br><span class="line">flann = cv.FlannBasedMatcher(index_params,search_params)</span><br><span class="line"> </span><br><span class="line">matches = flann.knnMatch(des1,des2,k=<span class="number">2</span>)</span><br><span class="line"> </span><br><span class="line"><span class="comment"># Need to draw only good matches, so create a mask</span></span><br><span class="line">matchesMask = [[<span class="number">0</span>,<span class="number">0</span>] <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(matches))]</span><br><span class="line"> </span><br><span class="line"><span class="comment"># ratio test as per Lowe&#x27;s paper</span></span><br><span class="line"><span class="keyword">for</span> i,(m,n) <span class="keyword">in</span> <span class="built_in">enumerate</span>(matches):</span><br><span class="line"> <span class="keyword">if</span> m.distance &lt; <span class="number">0.7</span>*n.distance:</span><br><span class="line">    matchesMask[i]=[<span class="number">1</span>,<span class="number">0</span>]</span><br><span class="line"> </span><br><span class="line">draw_params = <span class="built_in">dict</span>(matchColor = (<span class="number">0</span>,<span class="number">255</span>,<span class="number">0</span>),</span><br><span class="line"> singlePointColor = (<span class="number">255</span>,<span class="number">0</span>,<span class="number">0</span>),</span><br><span class="line"> matchesMask = matchesMask,</span><br><span class="line"> flags = cv.DrawMatchesFlags_DEFAULT)</span><br><span class="line"> </span><br><span class="line">img3 = cv.drawMatchesKnn(img1,kp1,img2,kp2,matches,<span class="literal">None</span>,**draw_params)</span><br><span class="line"> </span><br><span class="line">plt.imshow(img3,),plt.show()</span><br></pre></td></tr></table></figure>

<h4 id="3-特征匹配与单应实现物体查找"><a href="#3-特征匹配与单应实现物体查找" class="headerlink" title="3. 特征匹配与单应实现物体查找"></a>3. 特征匹配与单应实现物体查找</h4><p>前述的匹配是在另一张图片中寻找目标物体的一些部分.使用<code>cv.findHomography()</code>,传入两图片的点,可以找到物体在两个图片中的视角转换. 然后可以用<code>cv.perspectiveTransform</code>找到目标.至少需要4个正确的点来找到这个转换矩阵.</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> cv2 <span class="keyword">as</span> cv</span><br><span class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> pyplot <span class="keyword">as</span> plt</span><br><span class="line"> </span><br><span class="line">MIN_MATCH_COUNT = <span class="number">10</span></span><br><span class="line"> </span><br><span class="line">img1 = cv.imread(<span class="string">&#x27;images/box.png&#x27;</span>, cv.IMREAD_GRAYSCALE) <span class="comment"># queryImage</span></span><br><span class="line">img2 = cv.imread(<span class="string">&#x27;images/box_in_scene.png&#x27;</span>, cv.IMREAD_GRAYSCALE) <span class="comment"># trainImage</span></span><br><span class="line"> </span><br><span class="line"><span class="comment"># Initiate SIFT detector</span></span><br><span class="line">sift = cv.SIFT_create()</span><br><span class="line"> </span><br><span class="line"><span class="comment"># find the keypoints and descriptors with SIFT</span></span><br><span class="line">kp1, des1 = sift.detectAndCompute(img1,<span class="literal">None</span>)</span><br><span class="line">kp2, des2 = sift.detectAndCompute(img2,<span class="literal">None</span>)</span><br><span class="line"> </span><br><span class="line">FLANN_INDEX_KDTREE = <span class="number">1</span></span><br><span class="line">index_params = <span class="built_in">dict</span>(algorithm = FLANN_INDEX_KDTREE, trees = <span class="number">5</span>)</span><br><span class="line">search_params = <span class="built_in">dict</span>(checks = <span class="number">50</span>)</span><br><span class="line"> </span><br><span class="line">flann = cv.FlannBasedMatcher(index_params, search_params)</span><br><span class="line"> </span><br><span class="line">matches = flann.knnMatch(des1,des2,k=<span class="number">2</span>)</span><br><span class="line"> </span><br><span class="line"><span class="comment"># store all the good matches as per Lowe&#x27;s ratio test.</span></span><br><span class="line">good = []</span><br><span class="line"><span class="keyword">for</span> m,n <span class="keyword">in</span> matches:</span><br><span class="line"> <span class="keyword">if</span> m.distance &lt; <span class="number">0.7</span>*n.distance:</span><br><span class="line">    good.append(m)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> <span class="built_in">len</span>(good)&gt;MIN_MATCH_COUNT:</span><br><span class="line"> src_pts = np.float32([ kp1[m.queryIdx].pt <span class="keyword">for</span> m <span class="keyword">in</span> good ]).reshape(-<span class="number">1</span>,<span class="number">1</span>,<span class="number">2</span>)</span><br><span class="line"> dst_pts = np.float32([ kp2[m.trainIdx].pt <span class="keyword">for</span> m <span class="keyword">in</span> good ]).reshape(-<span class="number">1</span>,<span class="number">1</span>,<span class="number">2</span>)</span><br><span class="line"> </span><br><span class="line"> M, mask = cv.findHomography(src_pts, dst_pts, cv.RANSAC,<span class="number">5.0</span>)</span><br><span class="line"> matchesMask = mask.ravel().tolist()</span><br><span class="line"> </span><br><span class="line"> h,w = img1.shape</span><br><span class="line"> pts = np.float32([ [<span class="number">0</span>,<span class="number">0</span>],[<span class="number">0</span>,h-<span class="number">1</span>],[w-<span class="number">1</span>,h-<span class="number">1</span>],[w-<span class="number">1</span>,<span class="number">0</span>] ]).reshape(-<span class="number">1</span>,<span class="number">1</span>,<span class="number">2</span>)</span><br><span class="line"> dst = cv.perspectiveTransform(pts,M)</span><br><span class="line"> </span><br><span class="line"> img2 = cv.polylines(img2,[np.int32(dst)],<span class="literal">True</span>,<span class="number">255</span>,<span class="number">3</span>, cv.LINE_AA)</span><br><span class="line"> </span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line"> <span class="built_in">print</span>( <span class="string">&quot;Not enough matches are found - &#123;&#125;/&#123;&#125;&quot;</span>.<span class="built_in">format</span>(<span class="built_in">len</span>(good), MIN_MATCH_COUNT) )</span><br><span class="line"> matchesMask = <span class="literal">None</span></span><br><span class="line"></span><br><span class="line">draw_params = <span class="built_in">dict</span>(matchColor = (<span class="number">0</span>,<span class="number">255</span>,<span class="number">0</span>), <span class="comment"># draw matches in green color</span></span><br><span class="line"> singlePointColor = <span class="literal">None</span>,</span><br><span class="line"> matchesMask = matchesMask, <span class="comment"># draw only inliers</span></span><br><span class="line"> flags = <span class="number">2</span>)</span><br><span class="line"> </span><br><span class="line">img3 = cv.drawMatches(img1,kp1,img2,kp2,good,<span class="literal">None</span>,**draw_params)</span><br><span class="line"> </span><br><span class="line">plt.imshow(img3, <span class="string">&#x27;gray&#x27;</span>),plt.show()</span><br></pre></td></tr></table></figure>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://debugtheuniverse.github.io/2024/04/01/OpenCV%20%E7%89%B9%E5%BE%81%E5%8C%B9%E9%85%8D/" data-id="cluglu6mb0001i8uk4q3bc161" data-title="OpenCV 特征匹配" class="article-share-link"><span class="fa fa-share">Teilen</span></a>
      
      
      
    </footer>
  </div>
  
</article>



  
    <article id="post-OpenCV 相机畸变校准" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2024/03/28/OpenCV%20%E7%9B%B8%E6%9C%BA%E7%95%B8%E5%8F%98%E6%A0%A1%E5%87%86/" class="article-date">
  <time class="dt-published" datetime="2024-03-28T09:24:44.689Z" itemprop="datePublished">2024-03-28</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="p-name article-title" href="/2024/03/28/OpenCV%20%E7%9B%B8%E6%9C%BA%E7%95%B8%E5%8F%98%E6%A0%A1%E5%87%86/">OpenCV相机畸变校准</a>
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <h4 id="理论"><a href="#理论" class="headerlink" title="理论"></a>理论</h4><p>相机包含了径向畸变和切向畸变。<br>径向畸变可以让实际中的直线在图像中弯曲，这种效应离图像中心越远越强烈。<br>径向畸变表示为</p>
<center>
<img src="./assets/img/radial_dist.jpg" width="80%" height="80%">
</center>
切向畸变来自于镜片与传感器之间的平行度误差，导致有一些区域图像看起来比实际要近。
切向畸变表示为
<center>
<img src="./assets/img/tangential_dist.jpg" width="80%" height="80%">
</center>
因此需要找到如下畸变系数
<center>
<img src="./assets/img/dist_coef.jpg" width="50%" height="50%">
</center>

<p>此外，我们还需要获取相机的内参和外参。内参包括了焦距（f_x, f_y）和光学中心（c_x, c_y），可用来创建一个相机矩阵。而相机矩阵也是消除一个相机畸变需要的。相机矩阵是相机固有的属性，一旦求得，可以复用到同一相机的所有图片。</p>
<center>
<img src="./assets/img/camera_mtx.jpg" width="50%" height="50%">
</center>
外参对应了将3D点转换到一个坐标系的平移向量和旋转向量

<p>通常在立体视觉应用中，校正镜头畸变是必须的事情。校正的原理是，提供一些完好定义的样本图片（例如，棋盘图、圆点图），已知其上特征点的真实相对坐标，也知道对应点在图像上的坐标，就可以计算出来畸变系数。至少提供10张样本图片以确保好的效果。</p>
<h4 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h4><p>相机校正需要的输入是一系列3D真实点坐标和对应的2D图像坐标。在图像中找到2D坐标没有任何问题。但真实3D点坐标有点难了。为了简化，认为棋盘格都是在XY平面固定的，这样Z全是0，事情好办了起来。<br>在代码中,3D点是<code>object points</code>, 2D点是<code>image points</code></p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> cv2 <span class="keyword">as</span> cv</span><br><span class="line"><span class="keyword">import</span> glob</span><br><span class="line"></span><br><span class="line">criteria = (cv.TERM_CRITERIA_EPS + cv.TERM_CRITERIA_MAX_ITER, <span class="number">30</span>, <span class="number">0.001</span>)</span><br><span class="line"></span><br><span class="line">objp = np.zeros((<span class="number">6</span>*<span class="number">9</span>, <span class="number">3</span>), np.float32)</span><br><span class="line">objp[:,:<span class="number">2</span>] = np.mgrid[<span class="number">0</span>:<span class="number">9</span>, <span class="number">0</span>:<span class="number">6</span>].T.reshape(-<span class="number">1</span>,<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">objpoints = []  <span class="comment"># 真实世界的3D坐标</span></span><br><span class="line">imgpoints = []  <span class="comment"># 图像中的2D坐标</span></span><br><span class="line"></span><br><span class="line">images = glob.glob(<span class="string">&#x27;chessboard/*.jpg&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> fname <span class="keyword">in</span> images:</span><br><span class="line">    img = cv.imread(fname)</span><br><span class="line">    gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 寻找棋盘的角点</span></span><br><span class="line">    ret, corners = cv.findChessboardCorners(gray, (<span class="number">9</span>,<span class="number">6</span>),<span class="literal">None</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 如果找到了，加入目标点、图像点</span></span><br><span class="line">    <span class="keyword">if</span> ret == <span class="literal">True</span>:</span><br><span class="line">        objpoints.append(objp)</span><br><span class="line">        corners2 = cv.cornerSubPix(gray, corners, (<span class="number">11</span>,<span class="number">11</span>),(-<span class="number">1</span>,-<span class="number">1</span>),criteria)</span><br><span class="line">        imgpoints.append(corners2)</span><br><span class="line"></span><br><span class="line">        cv.drawChessboardCorners(img,(<span class="number">9</span>,<span class="number">6</span>),corners2,ret)</span><br><span class="line">        cv.imshow(<span class="string">&#x27;img&#x27;</span>, img)</span><br><span class="line">        cv.waitKey(<span class="number">500</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 校正 返回：ret、相机矩阵、扭曲系数、旋转向量s、平移向量s</span></span><br><span class="line">ret, mtx, dist, rvecs, tvecs = cv.calibrateCamera(objpoints, imgpoints, gray.shape[::-<span class="number">1</span>], <span class="literal">None</span>, <span class="literal">None</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 存储为npz文件，便于读取使用</span></span><br><span class="line">np.savez(<span class="string">&#x27;cameracalib&#x27;</span>,mtx=mtx, dist=dist, rvecs=rvecs, tvecs=tvecs)</span><br><span class="line">calib_file = np.load(<span class="string">&#x27;cameracalib.npz&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(calib_file[<span class="string">&#x27;mtx&#x27;</span>])</span><br><span class="line"></span><br><span class="line">img = cv.imread(<span class="string">&#x27;chessboard/left12.jpg&#x27;</span>)</span><br><span class="line">h, w = img.shape[:<span class="number">2</span>]</span><br><span class="line">newcameramtx, roi = cv.getOptimalNewCameraMatrix(calib_file[<span class="string">&#x27;mtx&#x27;</span>], calib_file[<span class="string">&#x27;dist&#x27;</span>], (w,h), <span class="number">1</span>, (w,h))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 消除畸变</span></span><br><span class="line">dst = cv.undistort(img,mtx, dist, <span class="literal">None</span>, newcameramtx)</span><br><span class="line">x,y,w,h = roi</span><br><span class="line">dst1 = dst[y:y+h, x:x+w]</span><br><span class="line">cv.imshow(<span class="string">&#x27;ds1&#x27;</span>,dst1)</span><br><span class="line">cv.imwrite(<span class="string">&#x27;calibresult.png&#x27;</span>, dst1)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 另一种方法消除畸变</span></span><br><span class="line">mapx, mapy = cv.initUndistortRectifyMap(mtx, dist, <span class="literal">None</span>, newcameramtx, (w,h), <span class="number">5</span>)</span><br><span class="line">dst2 = cv.remap(img, mapx, mapy, cv.INTER_LINEAR)</span><br><span class="line">dst2 = dst2[y:y+h, x:x+w]</span><br><span class="line">cv.imshow(<span class="string">&#x27;ds2&#x27;</span>,dst2)</span><br><span class="line"></span><br><span class="line">cv.waitKey(<span class="number">0</span>)</span><br><span class="line">cv.destroyAllWindows()</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>
      
    </div>
    <footer class="article-footer">
      <a data-url="https://debugtheuniverse.github.io/2024/03/28/OpenCV%20%E7%9B%B8%E6%9C%BA%E7%95%B8%E5%8F%98%E6%A0%A1%E5%87%86/" data-id="club3o6ez0000skukhea93hpf" data-title="OpenCV相机畸变校准" class="article-share-link"><span class="fa fa-share">Teilen</span></a>
      
      
      
    </footer>
  </div>
  
</article>



  
    <article id="post-OpenCV 特征提取" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2024/03/21/OpenCV%20%E7%89%B9%E5%BE%81%E6%8F%90%E5%8F%96/" class="article-date">
  <time class="dt-published" datetime="2024-03-21T08:49:51.831Z" itemprop="datePublished">2024-03-21</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="p-name article-title" href="/2024/03/21/OpenCV%20%E7%89%B9%E5%BE%81%E6%8F%90%E5%8F%96/">OpenCV 特征提取与描述</a>
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <h4 id="1-什么是特征"><a href="#1-什么是特征" class="headerlink" title="1. 什么是特征"></a>1. 什么是特征</h4><p>图像中的小区域，向周围小范围移动时变化最大，即特征。寻找到这些特征的过程叫做特征检测（Feature Detection）。<br>比如一个白色背景的矩形图像，位于四个角落的小区域是特征点，位于边线上的次要特征，位于纯色区域的没有特征</p>
<h4 id="2-Harris-角落检测"><a href="#2-Harris-角落检测" class="headerlink" title="2. Harris 角落检测"></a>2. Harris 角落检测</h4><p>寻找在全方向的（u,v）位移的亮度变化，形成函数，使用泰勒展开，推为矩阵M。创建一个分数R，取决于矩阵M的两个特征值之间的相对大小关系，判断为平区域、边界、角点</p>
<blockquote>
<p>R &#x3D; det(M) - k(trace(M))<sup>2</sup></p>
</blockquote>
<p>其中</p>
<ul>
<li>det(M) &#x3D; λ<sub>1</sub>λ<sub>2</sub></li>
<li>trace(M) &#x3D; λ<sub>1</sub> + λ<sub>2</sub></li>
<li>λ<sub>1</sub>和λ<sub>2</sub>是M的特征值</li>
</ul>
<p>代码使用<code>cv.cornerHarris()</code></p>
<ul>
<li>img -输入图像，灰度float32</li>
<li>blockSize -角点检测考虑的邻域大小</li>
<li>kSize -Sobel 微分使用的Aperture参数</li>
<li>k -Harris检测公式中的自由参数</li>
</ul>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> cv2 <span class="keyword">as</span> cv</span><br><span class="line"> </span><br><span class="line">filename = <span class="string">&#x27;calibresult.png&#x27;</span></span><br><span class="line">img = cv.imread(filename)</span><br><span class="line">gray = cv.cvtColor(img,cv.COLOR_BGR2GRAY)</span><br><span class="line"> </span><br><span class="line">gray = np.float32(gray)</span><br><span class="line">dst = cv.cornerHarris(gray,<span class="number">2</span>,<span class="number">3</span>,<span class="number">0.1</span>)</span><br><span class="line"> </span><br><span class="line"><span class="comment">#result is dilated for marking the corners, not important</span></span><br><span class="line">dst = cv.dilate(dst,<span class="literal">None</span>)</span><br><span class="line"> </span><br><span class="line"><span class="comment"># Threshold for an optimal value, it may vary depending on the image.</span></span><br><span class="line">img[dst&gt;<span class="number">0.01</span>*dst.<span class="built_in">max</span>()]=[<span class="number">0</span>,<span class="number">0</span>,<span class="number">255</span>]</span><br><span class="line"> </span><br><span class="line">cv.imshow(<span class="string">&#x27;dst&#x27;</span>,img)</span><br><span class="line"><span class="keyword">if</span> cv.waitKey(<span class="number">0</span>) &amp; <span class="number">0xff</span> == <span class="number">27</span>:</span><br><span class="line"> cv.destroyAllWindows()</span><br></pre></td></tr></table></figure>
<p>如果要获得亚像素精度的焦点，使用cv.cornerSubPix()</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># find centroids</span></span><br><span class="line">ret, labels, stats, centroids = cv.connectedComponentsWithStats(dst)</span><br><span class="line"> </span><br><span class="line"><span class="comment"># define the criteria to stop and refine the corners</span></span><br><span class="line">criteria = (cv.TERM_CRITERIA_EPS + cv.TERM_CRITERIA_MAX_ITER, <span class="number">100</span>, <span class="number">0.001</span>)</span><br><span class="line">corners = cv.cornerSubPix(gray,np.float32(centroids),(<span class="number">5</span>,<span class="number">5</span>),(-<span class="number">1</span>,-<span class="number">1</span>),criteria)</span><br></pre></td></tr></table></figure>
<h4 id="3-Shi-Tomasi-角点检测-Good-Features-to-Track"><a href="#3-Shi-Tomasi-角点检测-Good-Features-to-Track" class="headerlink" title="3. Shi-Tomasi 角点检测 Good Features to Track"></a>3. Shi-Tomasi 角点检测 Good Features to Track</h4><p>将分数定义为了</p>
<blockquote>
<p>R &#x3D; min(λ<sub>1</sub>, λ<sub>2</sub>)</p>
</blockquote>
<p>若R大于某个阈值，则认为是角点。</p>
<p>使用<code>cv.goodFeaturesToTrack()</code></p>
<ul>
<li>输入图像</li>
<li>需要寻找的角点数目</li>
<li>0-1之间的质量等级</li>
<li>角点之间的最小欧式距离<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">corners = cv.goodFeaturesToTrack(gray,<span class="number">250</span>,<span class="number">0.01</span>,<span class="number">20</span>)</span><br><span class="line">corners = np.int0(corners)</span><br><span class="line"> </span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> corners:</span><br><span class="line">    x,y = i.ravel()</span><br><span class="line">    cv.circle(img,(x,y),<span class="number">3</span>,<span class="number">255</span>,-<span class="number">1</span>)</span><br></pre></td></tr></table></figure></li>
</ul>
<h4 id="4-SIFT-尺度不变特征转换"><a href="#4-SIFT-尺度不变特征转换" class="headerlink" title="4. SIFT 尺度不变特征转换"></a>4. SIFT 尺度不变特征转换</h4><p>小窗口中的角点图被放大后，用同样大的窗口观察看起来变得平滑了。SIFT中，分别进行尺度空间极值检测、关键点定位、方向赋值、关键点描述、关键点匹配。这个算法在2020年专利已经到期，可放心使用。</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> cv2 <span class="keyword">as</span> cv</span><br><span class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> pyplot <span class="keyword">as</span> plt</span><br><span class="line"> </span><br><span class="line">filename = <span class="string">&#x27;images/home.jpg&#x27;</span></span><br><span class="line">img = cv.imread(filename)</span><br><span class="line">gray = cv.cvtColor(img,cv.COLOR_BGR2GRAY)</span><br><span class="line"></span><br><span class="line">sift = cv.SIFT_create()</span><br><span class="line">kp = sift.detect(gray,<span class="literal">None</span>)</span><br><span class="line"> </span><br><span class="line">img=cv.drawKeypoints(gray,kp,img)</span><br><span class="line"> </span><br><span class="line">cv.imwrite(<span class="string">&#x27;sift_keypoints.jpg&#x27;</span>,img)</span><br></pre></td></tr></table></figure>
<p><code>sift.detect()</code>可以输入mask指定寻找区域<br><code>cv.drawKeyPoints()</code>用于绘制关键点的圆圈，如果传入<code>flag=cv.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS</code>，会绘制关键点直径的圆圈并显示其方向。</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">img=cv.drawKeypoints(gray,kp,img,flags=cv.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)</span><br></pre></td></tr></table></figure>

<p>计算特征描述(Descriptor)</p>
<ol>
<li>已知关键点kp，用sift.compute(),&#96;&#96;kp, des &#x3D; sift.compute(gray, kp)</li>
<li>一步到位，用sift.detectdAndCompute()<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sift = cv.SIFT_create()</span><br><span class="line">kp, des = sift.detectAndCompute(gray,<span class="literal">None</span>)</span><br></pre></td></tr></table></figure>
kp是关键点列表，des是numpy数组形状是（关键点数）*128</li>
</ol>
<p>通常获得了关键点和描述，我们就可以在之后的操作中匹配不同图片中的关键点了。</p>
<h4 id="5-SURF-快速鲁棒特征"><a href="#5-SURF-快速鲁棒特征" class="headerlink" title="5. SURF 快速鲁棒特征"></a>5. SURF 快速鲁棒特征</h4><p>SURF在每个步骤增加了很多特征，达到同样效果比SIFT快3倍，适用于带有模糊和旋转的图片，但不适用视角转变和光线变化的情况。</p>
<p>如何在OpenCV中还处于专利保护阶段，要想使用，需要卸载当前高版本，重新安装opencv-contrib-python&#x3D;&#x3D;3.4.2.17</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 寻找SURF关键点和描述符并绘制</span></span><br><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line">img = cv2.imread(<span class="string">&#x27;images/fly.png&#x27;</span>, <span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建SURF对象，可以在创建时指定参数也可以稍后设置参数</span></span><br><span class="line"><span class="comment"># 此处设置 Hessian阈值为 400</span></span><br><span class="line">sift = cv2.xfeatures2d.SIFT_create()</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;sift: &#x27;</span>, sift)</span><br><span class="line">surf = cv2.xfeatures2d.SURF_create(<span class="number">400</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;surf: &#x27;</span>, surf,</span><br><span class="line">      <span class="string">&#x27; \ndefaultParameter\thessianThreshold: &#x27;</span>, surf.getHessianThreshold(),</span><br><span class="line">      <span class="string">&#x27; upright: &#x27;</span>, surf.getUpright(),</span><br><span class="line">      <span class="string">&#x27; extended: &#x27;</span>, surf.getExtended(),</span><br><span class="line">      <span class="string">&#x27; descriptors: &#x27;</span>,surf.descriptorSize())</span><br><span class="line"></span><br><span class="line"><span class="comment"># 寻找SURF关键点和描述符</span></span><br><span class="line"><span class="comment"># kp:返回的关键点列表，des：numpy数组</span></span><br><span class="line">kp, des = surf.detectAndCompute(img, <span class="literal">None</span>)</span><br><span class="line"><span class="comment"># 绘制关键点在图片上</span></span><br><span class="line">img2 = cv2.drawKeypoints(img, kp, <span class="literal">None</span>, (<span class="number">255</span>, <span class="number">0</span>, <span class="number">0</span>), <span class="number">4</span>)</span><br><span class="line">plt.imshow(img2), plt.xticks([]), plt.yticks([]), plt.title(<span class="string">&#x27;more keypoints&#x27;</span>), plt.show()</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;keypoints: &#x27;</span>, <span class="built_in">len</span>(kp))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 检查当前Hessian阈值</span></span><br><span class="line"><span class="comment"># print(surf.getHessianThreshold())</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 调整Hessian阈值，此处设置为50000，但一般最佳设置为300~500</span></span><br><span class="line">surf.setHessianThreshold(<span class="number">50000</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27; parameters\thessianThreshold: &#x27;</span>, surf.getHessianThreshold(),</span><br><span class="line">      <span class="string">&#x27; upright: &#x27;</span>, surf.getUpright(),</span><br><span class="line">      <span class="string">&#x27; extended: &#x27;</span>, surf.getExtended(),</span><br><span class="line">      <span class="string">&#x27; descriptors: &#x27;</span>,surf.descriptorSize())</span><br><span class="line"></span><br><span class="line"><span class="comment"># 再一次计算关键点和描述符</span></span><br><span class="line">kp, des = surf.detectAndCompute(img, <span class="literal">None</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;keypoints: &#x27;</span>, <span class="built_in">len</span>(kp))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 绘制关键点在图片上</span></span><br><span class="line">img2 = cv2.drawKeypoints(img, kp, <span class="literal">None</span>, (<span class="number">255</span>, <span class="number">0</span>, <span class="number">0</span>), <span class="number">4</span>)</span><br><span class="line"></span><br><span class="line">plt.imshow(img2), plt.xticks([]), plt.yticks([]), plt.title(<span class="string">&#x27;less than 50 keypoints&#x27;</span>), plt.show()</span><br><span class="line"></span><br><span class="line"><span class="comment"># U-SURF不会计算方向</span></span><br><span class="line"><span class="comment"># print(surf.getUpright())</span></span><br><span class="line">surf.setUpright(<span class="literal">True</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27; parameters\thessianThreshold: &#x27;</span>, surf.getHessianThreshold(),</span><br><span class="line">      <span class="string">&#x27; upright: &#x27;</span>, surf.getUpright(),</span><br><span class="line">      <span class="string">&#x27; extended: &#x27;</span>, surf.getExtended(),</span><br><span class="line">      <span class="string">&#x27; descriptors: &#x27;</span>,surf.descriptorSize())</span><br><span class="line"></span><br><span class="line"><span class="comment"># 重新计算关键点和描述符，并绘制</span></span><br><span class="line">kp = surf.detect(img, <span class="literal">None</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;keypoints: &#x27;</span>, <span class="built_in">len</span>(kp))</span><br><span class="line">img2 = cv2.drawKeypoints(img, kp, <span class="literal">None</span>, (<span class="number">255</span>, <span class="number">0</span>, <span class="number">0</span>), <span class="number">4</span>)</span><br><span class="line"></span><br><span class="line">plt.imshow(img2), plt.xticks([]), plt.yticks([]), plt.title(<span class="string">&#x27;U-SURF&#x27;</span>), plt.show()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 所有方向显示在同一方向，它比以前快多了。如果您正在处理方向不成问题的情况（如全景缝合）等，使用U-SURF会更好。</span></span><br><span class="line"><span class="comment"># 寻找描述符的大小</span></span><br><span class="line"><span class="comment"># print(surf.descriptorSize())</span></span><br><span class="line"><span class="comment"># extended为false，默认为64D</span></span><br><span class="line"><span class="comment"># print(surf.getExtended())</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置描述符为128D</span></span><br><span class="line">surf.setExtended(<span class="literal">True</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27; parameters\thessianThreshold: &#x27;</span>, surf.getHessianThreshold(),</span><br><span class="line">      <span class="string">&#x27; upright: &#x27;</span>, surf.getUpright(),</span><br><span class="line">      <span class="string">&#x27; extended: &#x27;</span>, surf.getExtended(),</span><br><span class="line">      <span class="string">&#x27; descriptors: &#x27;</span>,surf.descriptorSize())</span><br><span class="line"></span><br><span class="line">kp, des = surf.detectAndCompute(img, <span class="literal">None</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;keypoints: &#x27;</span>,<span class="built_in">len</span>(kp))</span><br><span class="line">img2 = cv2.drawKeypoints(img, kp, <span class="literal">None</span>, (<span class="number">255</span>, <span class="number">0</span>, <span class="number">0</span>), <span class="number">4</span>)</span><br><span class="line"></span><br><span class="line">plt.imshow(img2), plt.xticks([]), plt.yticks([]), plt.title(<span class="string">&#x27;128D res&#x27;</span>), plt.show()</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>代码<a target="_blank" rel="noopener" href="https://juejin.cn/post/7023698517327609887">来自这</a></p>
<h4 id="6-FAST-快速角点检测方法"><a href="#6-FAST-快速角点检测方法" class="headerlink" title="6. FAST 快速角点检测方法"></a>6. FAST 快速角点检测方法</h4><p>比前几种方法快几倍，但对高噪音不鲁棒。有一个阈值参数。</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> cv2 <span class="keyword">as</span> cv</span><br><span class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> pyplot <span class="keyword">as</span> plt</span><br><span class="line"> </span><br><span class="line">img = cv.imread(<span class="string">&#x27;images/blox.jpg&#x27;</span>, cv.IMREAD_GRAYSCALE) <span class="comment"># `&lt;opencv_root&gt;/samples/data/blox.jpg`</span></span><br><span class="line"> </span><br><span class="line"><span class="comment"># Initiate FAST object with default values</span></span><br><span class="line">fast = cv.FastFeatureDetector_create()</span><br><span class="line"> </span><br><span class="line"><span class="comment"># find and draw the keypoints</span></span><br><span class="line">kp = fast.detect(img,<span class="literal">None</span>)</span><br><span class="line">img2 = cv.drawKeypoints(img, kp, <span class="literal">None</span>, color=(<span class="number">255</span>,<span class="number">0</span>,<span class="number">0</span>))</span><br><span class="line"> </span><br><span class="line"><span class="comment"># Print all default params</span></span><br><span class="line"><span class="built_in">print</span>( <span class="string">&quot;Threshold: &#123;&#125;&quot;</span>.<span class="built_in">format</span>(fast.getThreshold()) )</span><br><span class="line"><span class="built_in">print</span>( <span class="string">&quot;nonmaxSuppression:&#123;&#125;&quot;</span>.<span class="built_in">format</span>(fast.getNonmaxSuppression()) )</span><br><span class="line"><span class="built_in">print</span>( <span class="string">&quot;neighborhood: &#123;&#125;&quot;</span>.<span class="built_in">format</span>(fast.getType()) )</span><br><span class="line"><span class="built_in">print</span>( <span class="string">&quot;Total Keypoints with nonmaxSuppression: &#123;&#125;&quot;</span>.<span class="built_in">format</span>(<span class="built_in">len</span>(kp)) )</span><br><span class="line"> </span><br><span class="line">cv.imwrite(<span class="string">&#x27;fast_true.png&#x27;</span>, img2)</span><br><span class="line"> </span><br><span class="line"><span class="comment"># Disable nonmaxSuppression</span></span><br><span class="line">fast.setNonmaxSuppression(<span class="number">0</span>)</span><br><span class="line">kp = fast.detect(img, <span class="literal">None</span>)</span><br><span class="line"> </span><br><span class="line"><span class="built_in">print</span>( <span class="string">&quot;Total Keypoints without nonmaxSuppression: &#123;&#125;&quot;</span>.<span class="built_in">format</span>(<span class="built_in">len</span>(kp)) )</span><br><span class="line"> </span><br><span class="line">img3 = cv.drawKeypoints(img, kp, <span class="literal">None</span>, color=(<span class="number">255</span>,<span class="number">0</span>,<span class="number">0</span>))</span><br><span class="line"> </span><br><span class="line">cv.imwrite(<span class="string">&#x27;fast_false.png&#x27;</span>, img3)</span><br></pre></td></tr></table></figure>

<h4 id="7-BRIEF-二元鲁棒独立基本特征"><a href="#7-BRIEF-二元鲁棒独立基本特征" class="headerlink" title="7. BRIEF 二元鲁棒独立基本特征"></a>7. BRIEF 二元鲁棒独立基本特征</h4><p>一种更快的特征描述与匹配方法，需要使用其他的方法检测到关键点，适用于CenSurE（STAR）方法</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> cv2 <span class="keyword">as</span> cv</span><br><span class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> pyplot <span class="keyword">as</span> plt</span><br><span class="line"> </span><br><span class="line">img = cv.imread(<span class="string">&#x27;images/aero1.jpg&#x27;</span>, cv.IMREAD_GRAYSCALE)</span><br><span class="line"> </span><br><span class="line"><span class="comment"># Initiate FAST detector</span></span><br><span class="line">fast = cv.xfeatures2d.StarDetector_create()</span><br><span class="line"> </span><br><span class="line"><span class="comment"># Initiate BRIEF extractor</span></span><br><span class="line">brief = cv.xfeatures2d.BriefDescriptorExtractor_create()</span><br><span class="line"> </span><br><span class="line"><span class="comment"># find the keypoints with STAR</span></span><br><span class="line">kp = fast.detect(img,<span class="literal">None</span>)</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"><span class="comment"># compute the descriptors with BRIEF</span></span><br><span class="line">kp, des = brief.compute(img, kp)</span><br><span class="line"> </span><br><span class="line"><span class="built_in">print</span>( brief.descriptorSize() )</span><br><span class="line"><span class="built_in">print</span>( des.shape )</span><br></pre></td></tr></table></figure>

<h4 id="8-ORB（Oriented-FAST-and-Rotated-BRIEF）"><a href="#8-ORB（Oriented-FAST-and-Rotated-BRIEF）" class="headerlink" title="8. ORB（Oriented FAST and Rotated BRIEF）"></a>8. ORB（Oriented FAST and Rotated BRIEF）</h4><p>没有专利，安全使用，更快更好。</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> cv2 <span class="keyword">as</span> cv</span><br><span class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> pyplot <span class="keyword">as</span> plt</span><br><span class="line"> </span><br><span class="line">img = cv.imread(<span class="string">&#x27;images/blox.jpg&#x27;</span>, cv.IMREAD_GRAYSCALE)</span><br><span class="line"> </span><br><span class="line"><span class="comment"># Initiate ORB detector</span></span><br><span class="line">orb = cv.ORB_create()</span><br><span class="line"> </span><br><span class="line"><span class="comment"># find the keypoints with ORB</span></span><br><span class="line">kp = orb.detect(img,<span class="literal">None</span>)</span><br><span class="line"> </span><br><span class="line"><span class="comment"># compute the descriptors with ORB</span></span><br><span class="line">kp, des = orb.compute(img, kp)</span><br><span class="line"> </span><br><span class="line"><span class="comment"># draw only keypoints location,not size and orientation</span></span><br><span class="line">img2 = cv.drawKeypoints(img, kp, <span class="literal">None</span>, color=(<span class="number">0</span>,<span class="number">255</span>,<span class="number">0</span>), flags=<span class="number">0</span>)</span><br><span class="line">plt.imshow(img2), plt.show()</span><br></pre></td></tr></table></figure>

<p>具体使用直接看<a target="_blank" rel="noopener" href="https://docs.opencv.org/4.x/db/d27/tutorial_py_table_of_contents_feature2d.html">官方教程</a></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://debugtheuniverse.github.io/2024/03/21/OpenCV%20%E7%89%B9%E5%BE%81%E6%8F%90%E5%8F%96/" data-id="clu1zw4kt0000oguk8svc9jox" data-title="OpenCV 特征提取与描述" class="article-share-link"><span class="fa fa-share">Teilen</span></a>
      
      
      
    </footer>
  </div>
  
</article>



  


  <nav id="page-nav">
    
    <a class="extend prev" rel="prev" href="/">&laquo; zurück</a><a class="page-number" href="/">1</a><span class="page-number current">2</span><a class="page-number" href="/page/3/">3</a><a class="extend next" rel="next" href="/page/3/">weiter &raquo;</a>
  </nav>

</section>
        
          <aside id="sidebar">
  
    

  
    

  
    
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archiv</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2024/10/">October 2024</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2024/09/">September 2024</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2024/08/">August 2024</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2024/05/">May 2024</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2024/04/">April 2024</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2024/03/">March 2024</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">letzter Beitrag</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2024/10/09/%E6%9C%BA%E5%99%A8%E4%BA%BA%E8%B7%AF%E5%BE%84%E8%A7%84%E5%88%92/">机器人路径规划</a>
          </li>
        
          <li>
            <a href="/2024/09/09/CMakeList%E6%95%99%E7%A8%8B/">CMakeList教程</a>
          </li>
        
          <li>
            <a href="/2024/08/22/MCL%20%E8%92%99%E7%89%B9%E5%8D%A1%E6%B4%9B%E5%AE%9A%E4%BD%8D/">MCL 蒙特卡洛定位</a>
          </li>
        
          <li>
            <a href="/2024/08/22/Kalman%E6%BB%A4%E6%B3%A2/">Kalman滤波</a>
          </li>
        
          <li>
            <a href="/2024/05/14/Python%20advanced/">(no title)</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      
      &copy; 2024 Jim Huang<br>
      Powered by <a href="https://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>

    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    


<script src="/js/jquery-3.6.4.min.js"></script>



  
<script src="/fancybox/jquery.fancybox.min.js"></script>




<script src="/js/script.js"></script>





  </div>
</body>
</html>